
<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8" />
        <title>LinkedList&#39;s Blog</title>
        <meta name="author" content="Ding Li" />
        <meta name="description" content="This is blog for Linkedlist771, mainly record some learning notes, thank you for your visit!" />
        <meta name="keywords" content="" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
        <link rel="icon" href="/images/favicon.png" />
        <script src="https://cdn.staticfile.org/vue/3.2.47/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/6.3.0/css/all.min.css" />
<link rel="stylesheet" href="/css/fonts.min.css" />
<script> const mixins = {}; </script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=default"></script>


<script src="https://cdn.staticfile.org/highlight.js/11.7.0/highlight.min.js"></script>
<link
    rel="stylesheet"
    href="https://cdn.staticfile.org/highlight.js/11.7.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>


<script src="https://cdn.staticfile.org/KaTeX/0.16.4/katex.min.js"></script>
<script src="https://cdn.staticfile.org/KaTeX/0.16.4/contrib/auto-render.min.js"></script>
<link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.16.4/katex.min.css" />
<script src="/js/lib/math.js"></script>


<script src="/js/lib/preview.js"></script>





<script src="/js/lib/home.js"></script>

<link rel="stylesheet" href="/css/main.css" />

    <meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <div id="layout">
            <transition name="fade">
                <div id="loading" v-show="loading">
                    <div id="loading-circle">
                        <h2>LOADING</h2>
                        <p>加载过慢请开启缓存 浏览器默认开启</p>
                        <img src="/images/loading.gif" />
                    </div>
                </div>
            </transition>
            <nav id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <div id="desktop-menu">
        <a class="title" href="/">
            <span>LINKEDLIST&#39;S BLOG</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </div>
    <div id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;LINKEDLIST&#39;S BLOG</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </div>
</nav>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

            <transition name="into">
                <div id="main" v-show="!loading">
                    <div id="home-head">
    <div id="home-background" ref="homeBackground" data-images="/images/background1.jpg"></div>
    <div id="home-info" @click="homeClick">
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="loop"></span>
        <span class="info">
            <div class="wrap">
                <h1>LinkedList&#39;s Blog</h1>
                <h3>Learning notes</h3>
                <h5>This is blog for Linkedlist771, mainly record some learning notes, thank you for your visit!</h5>
            </div>
        </span>
    </div>
</div>
<div id="home-posts-wrap"  ref="homePostsWrap">
    <div id="home-posts">
        

<div class="post">
    <a href="/2023/07/02/DeepMD%E8%AF%A6%E7%BB%86%E5%86%85%E5%AE%B9%E4%BB%8B%E7%BB%8D/">
        <h2 class="post-title">DeepMD详细内容介绍</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/7/2
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h1 id="DeePMD-调研报告"><a href="#DeePMD-调研报告" class="headerlink" title="DeePMD 调研报告"></a>DeePMD 调研报告</h1><ul>
<li><a href="#%E7%AE%80%E4%BB%8B">简介</a></li>
<li><a href="#%E8%83%8C%E6%99%AF%E5%92%8C%E5%8A%A8%E6%9C%BA">背景和动机</a></li>
<li><a href="#deepmd-kit-%E6%A6%82%E8%BF%B0">DeePMD-kit 概述</a></li>
<li><a href="#%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95">核心算法</a></li>
<li><a href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84">代码实现和网络架构</a></li>
<li><a href="#%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8-deepmd-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8">图神经网络在 DeePMD 中的应用</a></li>
<li><a href="#%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B">应用案例</a></li>
<li><a href="#%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0">性能评估</a></li>
<li><a href="#%E4%B8%8E%E5%85%B6%E4%BB%96%E5%B7%A5%E5%85%B7%E7%9A%84%E6%AF%94%E8%BE%83">与其他工具的比较</a></li>
<li><a href="#%E7%A4%BE%E5%8C%BA%E5%92%8C%E8%B5%84%E6%BA%90">社区和资源</a></li>
<li><a href="#%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B">未来展望</a></li>
<li><a href="#%E7%BB%93%E8%AE%BA">结论</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE">参考文献</a></li>
</ul>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>分子动力学（MD）模拟在凝聚态物理、材料科学、聚合物化学和分子生物学等领域具有广泛的应用，它允许研究人员检查原子或分子的行为，这在实验难以进行时尤为宝贵。然而，MD模拟的质量受到势能（PES）准确性的限制。传统上，有两种常见的模型：经验性原子势模型和量子力学模型。经验性原子势模型在计算上高效但准确性有限，而量子力学模型虽然准确度高，但计算成本很高。近年来，机器学习（ML）模型开始崭露头角，用于解决准确性和效率之间的权衡问题。ML模型通过训练来建立原子配置和势能之间的关系，并能达到与量子力学方法相当的准确性，同时具有更低的计算成本。深度势（DP）模型是ML模型的一种，它不仅具有量子力学精度，而且具有高计算效率，并且是端到端的，支持在现代高性能计算机上高效运行。</p>
<p><img src="/../images/image-20230701141805592.png" alt="image-20230701141805592"></p>
<h2 id="DeePMD-kit-概述"><a href="#DeePMD-kit-概述" class="headerlink" title="DeePMD-kit 概述"></a>DeePMD-kit 概述</h2><p>DeePMD-kit 是一个使用深度学习模型来高效模拟分子动力学的工具包。下面是相关的参考内容：</p>
<ul>
<li><strong><a target="_blank" rel="noopener" href="https://docs.deepmodeling.com/projects/deepmd/en/master/index.html">文档</a></strong></li>
<li><strong><a target="_blank" rel="noopener" href="https://tutorials.deepmodeling.com/en/latest/">Tutorial</a></strong></li>
<li><strong><a target="_blank" rel="noopener" href="https://github.com/deepmodeling">GitHub主页</a></strong></li>
<li><strong><a target="_blank" rel="noopener" href="https://www.aissquare.com/">数据集和模型的共享平台</a></strong></li>
</ul>
<p><img src="/../images/image-20230701154308257.png" alt="figure"></p>
<!-- <img src="../images/image-20230701154308257.png" alt="image-20230701154308257" style="zoom:67%;" /> -->

<h3 id="DeePMD-kit-的工作流程"><a href="#DeePMD-kit-的工作流程" class="headerlink" title="DeePMD-kit 的工作流程"></a>DeePMD-kit 的工作流程</h3><ol>
<li><p><strong>准备训练数据</strong>：从量子力学模拟收集原子配置和相应的能量和力。</p>
</li>
<li><p><strong>配置 DeePMD-kit</strong>：创建输入文件，指定训练数据、神经网络结构和训练参数。</p>
</li>
<li><p><strong>描述符生成</strong>：DeePMD-kit 使用局部环境矩阵 $ \mathcal{R} $，它描述了特定原子及其邻居之间的距离和方向向量。</p>
</li>
<li><p><strong>嵌入网络</strong>：将每个距离嵌入到 $ M_1 $ 维向量中，从而将环境矩阵 $ \mathcal{R} $ 嵌入到矩阵 $ \mathcal{G} $ 中。</p>
</li>
<li><p><strong>拟合网络</strong>：通过矩阵乘法从 $ \mathcal{G} $ 中提取描述符向量，然后将描述符输入到拟合网络以获得预测能量。</p>
</li>
<li><p><strong>原子类型嵌入</strong>：DeePMD-kit v2.0 允许在不同原子类型之间共享嵌入网络和拟合网络，从而降低训练复杂性。</p>
</li>
</ol>
<p><img src="/../images/image-20230701140012565.png" alt="figure"><br><img src="/../images/image-20230701140054102.png" alt="figure"></p>
<!-- 

<img src="../images/image-20230701140012565.png" alt="image-20230701140012565" style="zoom:50%;" />
<img src="../images/image-20230701140054102.png" alt="image-20230701140054102" style="zoom:50%;" /> -->

<h3 id="DeePMD-kit-的原理"><a href="#DeePMD-kit-的原理" class="headerlink" title="DeePMD-kit 的原理"></a>DeePMD-kit 的原理</h3><h4 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h4><p>在介绍DP方法之前，我们定义了一个包含N个原子的系统的坐标矩阵$\mathcal{R} \in \mathbb{R}^{N \times 3}$，</p>
<p>$\mathcal{R}&#x3D;\left{\boldsymbol{r}_1^T, \cdots, \boldsymbol{r}_i^T, \cdots, \boldsymbol{r}_N^T\right}^T, \boldsymbol{r}_i&#x3D;\left(x_i, y_i, z_i\right),(1)$</p>
<p>$\boldsymbol{r}<em>i$包含原子$i$的3个笛卡尔坐标，$\boldsymbol{\mathcal { R }}$可以转换为局部环境矩阵$\left{\boldsymbol{\mathcal { R }}^i\right}</em>{i&#x3D;1}^N$</p>
<p>$\mathcal{R}^i&#x3D;\left{\boldsymbol{r}<em>{1 i}^T, \cdots, \boldsymbol{r}</em>{j i}^T, \cdots, \boldsymbol{r}<em>{N_i, i}^T\right}^T, \boldsymbol{r}</em>{j i}&#x3D;\left(x_{j i}, y_{j i}, z_{j i}\right),(2)$</p>
<p>其中$j$和$N_i$是原子$i$在截止半径$r_c$内的邻居的索引，$\boldsymbol{r}_{j i} \equiv \boldsymbol{r}_j-\boldsymbol{r}_i$被定义为相对坐标。<br>在DP方法中，系统的总能量$E$被构造为原子能量的总和。</p>
<p>$E&#x3D;\sum_i E_i,(3)$</p>
<p>其中$E_i$是原子$i$的局部原子能量。$E_i$取决于原子$i$的局部环境：</p>
<p>$E&#x3D;\sum_i E_i&#x3D;\sum_i E\left(\mathcal{R}^i\right),(4)$</p>
<p>$\mathcal{R}^i$到$E_i$的映射分两步构造。如下图所示，</p>
<p><img src="https://dp-public.oss-cn-beijing.aliyuncs.com/20220523-143747.png" alt="figure"></p>
<p>首先，$\mathcal{R}^i$被映射到一个特征矩阵，也称为描述符，$\mathcal{D}^i$，以保持系统的平移、旋转和排列对称性。$\mathcal{R}^i \in \mathbb{R}^{N_i \times 3}$首先被转换为广义坐标$\tilde{\mathcal{R}}^i \in \mathbb{R}^{N_i \times 4}$。</p>
<p>$\left{x_{j i}, y_{j i}, z_{j i}\right} \mapsto\left{s\left(r_{j i}\right), \hat{x}<em>{j i}, \hat{y}</em>{j i}, \hat{z}_{j i}\right}$</p>
<p>其中$\hat{x}<em>{j i}&#x3D;\frac{s\left(r</em>{j j}\right) x x_{j i}}{r_{j i}}, \hat{y}<em>{j i}&#x3D;\frac{s\left(r</em>{j j}\right) y \ddot{j}}{r_{j i}}$, 和 $\hat{z}<em>{j i}&#x3D;\frac{s\left(r</em>{j j}\right) z j i}{r_{j i}}$。$s\left(r_{j i}\right)$是一个权重函数，用于减少离原子$i$较远的粒子的权重，定义为：</p>
<p>$s\left(r_{j i}\right)&#x3D; \begin{cases}\frac{1}{r_{j i}}, &amp; r_{j i}&lt;r_{c s} \ \frac{1}{r_{j i}}\left{\left(\frac{r_{j i}-r_{c s}}{r_c-r_{c s}}\right)^3\left(-6\left(\frac{r_{j j}-r_{c s}}{r_c-r_{c s}}\right)^2+15 \frac{r_{j j}-r_{c s}}{r_c-r_{c s}}-10\right)+1\right}, &amp; r_{c s}&lt;r_{j i}&lt;r_c,(6) \ 0, &amp; r_{j i}&gt;r_c\end{cases}$</p>
<p>这里$r_{j i}$是原子$i$和$j$之间的欧几里得距离，$r_{c s}$是平滑截止参数。通过引入$s\left(r_{j i}\right)$，$\tilde{\mathcal{R}}^i$中的分量从$r_{c s}$到$r_c$平滑地变为零。然后，$s\left(r_{j i}\right)$，即$\tilde{\mathcal{R}}^i$的第一列，通过嵌入神经网络映射到嵌入矩阵$\mathcal{G}^{i 2} \in \mathbb{R}^{N_i \times M_1}$。通过取$\mathcal{G}^{i 2} \in \mathbb{R}^{N_i \times M_2}$的前$M_2\left(&lt;M_1\right)$列，我们得到另一个嵌入矩阵$\mathcal{G}^{i 2} \in \mathbb{R}^{N_i \times M_2}$。最后，我们定义原子$i$的特征矩阵$\mathcal{G}^{i 2} \in \mathbb{R}^{M_1 \times M_2}$：</p>
<p>$\mathcal{D}^i&#x3D;\left(\mathcal{G}^{i 1}\right)^T \tilde{\mathcal{R}}^i\left(\tilde{\mathcal{R}}^i\right)^T \mathcal{G}^{i 2},(7)$</p>
<p>在特征矩阵中，通过$\tilde{\mathcal{R}}^i\left(\tilde{\mathcal{R}}^i\right)^T$的矩阵乘积保持平移和旋转对称性，并通过$\left(\mathcal{G}^i\right)^T \tilde{\mathcal{R}}^i$的矩阵乘积保持排列对称性。接下来，每个$\mathcal{D}^i$通过拟合网络映射到局部原子能量$E_i$。</p>
<p>嵌入网络$\mathcal{N}^e$和拟合网络$\mathcal{N}^f$都是包含几个隐藏层的前馈神经网络。从前一层的输入数据$d_l^{\text {in }}$到下一层的输出数据$d_k^{\text {out }}$的映射由线性和非线性变换组成。</p>
<p>$d_k^{o u t}&#x3D;\varphi\left(\sum_{k l} w_{k l} d_l^{i n}+b_k\right),(8)$</p>
<p>在等式(8)中，$w_{k l}$是连接权重，$b_k$是偏置权重，$\varphi$是非线性激活函数。需要注意的是，只在输出节点应用线性变换。嵌入和拟合网络中包含的参数是通过最小化损失函数$L$获得的：</p>
<p>$L\left(p_\epsilon, p_f, p_{\xi}\right)&#x3D;\frac{p_\epsilon}{N} \Delta \epsilon^2+\frac{p_f}{3 N} \sum_i\left|\Delta \boldsymbol{F}<em>i\right|^2+\frac{p</em>{\xi}}{9 N}|\Delta \xi|^2,(9)$</p>
<p>其中$\Delta \epsilon, \Delta \boldsymbol{F}<em>i$, 和 $\Delta \xi$分别表示能量、力和应力的均方根误差。在训练过程中，前因子$p_\epsilon, p_f$, 和 $p</em>{\xi}$由以下公式确定</p>
<p>$p(t)&#x3D;p^{\operatorname{limit}}\left[1-\frac{r_l(t)}{r_l^0}\right]+p^{\operatorname{start}}\left[\frac{r_l(t)}{r_l^0}\right]$</p>
<p>其中$r_l(t)$和$r_l^0$分别是训练步骤$t$和训练步骤0的学习率。$r_l(t)$定义为</p>
<p>$r_l(t)&#x3D;r_l^0 \times d_r^{t &#x2F; d_s}$</p>
<p>其中$d_r$和$d_s$分别是衰减率和衰减步骤。衰减率$d_r$需要小于1。有关DeepPot-SE (DP)方法的详细信息，请参阅原始论文。</p>
<h4 id="分子动力学"><a href="#分子动力学" class="headerlink" title="分子动力学"></a>分子动力学</h4><p>分子动力学模拟是一种从微观出发的模拟手段，在科学发现，工程设计等领域具有重要作用。</p>
<p>$\begin{aligned}<br>&amp; m_i \frac{d^2 \boldsymbol{r}_i}{d t^2}&#x3D;-\nabla_i E \<br>&amp; E&#x3D;E\left(\boldsymbol{r}_1, \boldsymbol{r}_2, \ldots, \boldsymbol{r}_N\right)<br>\end{aligned}$</p>
<ul>
<li>计算能量的常见的方式</li>
</ul>
<table>
<thead>
<tr>
<th>方法</th>
<th>例子</th>
<th>优缺点</th>
</tr>
</thead>
<tbody><tr>
<td>第一性原理计算密度泛函理论(DFT)</td>
<td>密度泛函理论(DFT)</td>
<td>精度高，计算复杂度高</td>
</tr>
<tr>
<td>计算经验力场</td>
<td>LJ，EAM，MEAM</td>
<td>计算复杂度低，精度不可靠</td>
</tr>
</tbody></table>
<h4 id="DeePKS（电子结构）"><a href="#DeePKS（电子结构）" class="headerlink" title="DeePKS（电子结构）"></a>DeePKS（电子结构）</h4><p><img src="/../images/image-20230701173718442.png" alt="figure"></p>
<!-- <img src="../images/image-20230701173718442.png" alt="image-20230701173718442" style="zoom:67%;" /> -->

<p>满足要求比较好的是<code>单电子的密度矩阵</code>， 然后把波函数投影到一组比较好的<code>完备基</code>上。<br><img src="/../images/image-20230701175149730.png" alt="figure"></p>
<!-- <img src="../images/image-20230701175149730.png" alt="image-20230701175149730" style="zoom:67%;" /> -->



<h4 id><a href="#" class="headerlink" title></a></h4><p><img src="/../images/image-20230701175739715.png" alt="figure"></p>
<!-- <img src="../images/image-20230701175739715.png" alt="image-20230701175739715" style="zoom:67%;" /> -->

<p>构建过程</p>
<p><img src="/../images/image-20230701143507583.png" alt="image-20230701143507583"></p>
<ol>
<li>给定原子坐标， 写出电子结构， 利用DFT计算得到能量， 构建坐标能量对，典型的<code>监督学习</code>，<code>回归</code>问题。</li>
<li>利用DNN来构建<code>体系坐标</code>和<code>能量</code>的关系。</li>
</ol>
<ul>
<li><p>常见的问题： </p>
</li>
<li><ul>
<li>物理约束（旋转性，对称性， 平移， 交换…）</li>
</ul>
</li>
</ul>
<p><img src="/../images/image-20230701143814105.png" alt="figure"></p>
  <!-- <img src="../images/image-20230701143814105.png" alt="image-20230701143814105" style="zoom: 67%;" /> -->

<ul>
<li><p>小原子数量训练得到的在大体系上是否存在问题？</p>
</li>
<li><p>深度势能的构建关系<br>$<br>E&#x3D;\sum_i \mathcal{N}<em>{\alpha_i}\left(\mathcal{D}</em>{\alpha_i}\left(r_i,\left{r_j\right}_{j \in n(i)}\right)\right)<br>$</p>
</li>
</ul>
<p><img src="/../images/image-20230701144137434.png" alt="figure"></p>
<!-- <img src="../images/image-20230701144137434.png" alt="image-20230701144137434" style="zoom: 67%;" /> -->

<p>Function $f\left(x_1, x_2, \ldots x_N\right)$ is permutationally invariant if and only if there exist $\rho$ and $\phi$ such that $f\left(\left{x_i\right}\right)&#x3D;\rho\left(\sum_i \phi\left(x_i\right)\right)$<br>$<br>\mathcal{R}<em>i&#x3D;\left(\begin{array}{cccc}<br>1 &#x2F; r</em>{i 1} &amp; x_{i 1} &#x2F; r_{i 1}^2 &amp; y_{i 1} &#x2F; r_{i 1}^2 &amp; z_{i 1} &#x2F; r_{i 1}^2 \<br>1 &#x2F; r_{i 2} &amp; x_{i 2} &#x2F; r_{i 2}^2 &amp; y_{i 2} &#x2F; r_{i 2}^2 &amp; z_{i 2} &#x2F; r_{i 2}^2 \<br>1 &#x2F; r_{i 3} &amp; x_{i 3} &#x2F; r_{i 3}^2 &amp; y_{i 3} &#x2F; r_{i 3}^2 &amp; z_{i 3} &#x2F; r_{i 3}^2 \</p>
<p>\vdots &amp; \vdots &amp; \vdots &amp; \vdots<br>\end{array}\right) \<br>\mathcal{G}_i&#x3D;\left(\begin{array}{cccc}</p>
<p>G_1\left(r_{i 1}\right)  G_2\left(r_{i 1}\right) &amp; G_3\left(r_{i 1}\right) &amp; \cdots \<br>G_1\left(r_{i 2}\right) &amp; G_2\left(r_{i 2}\right) &amp; G_3\left(r_{i 2}\right) &amp; \cdots \<br>G_1\left(r_{i 3}\right) &amp; G_2\left(r_{i 3}\right) &amp; G_3\left(r_{i 3}\right) &amp; \cdots \<br>\vdots &amp; \vdots &amp; \vdots &amp; \ddots<br>\end{array}\right)<br>$</p>
<blockquote>
<p>R： 环境矩阵， 对于每一个原子来说的， 元素是原子之间的相对距离，所以满足平移相对性， </p>
<p>G： embedding matrix。<br><img src="/../images/image-20230701144137434.png" alt="figure"></p>
</blockquote>
<!-- <img src="../images/image-20230701144805918.png" alt="image-20230701144805918" style="zoom:67%;" /> -->

<p>周期不变：<br>$<br>\mathcal{D}_i&#x3D;\left(\mathcal{G}_i^{&lt;}\right)^T \mathcal{R}_i\left(\mathcal{R}_i\right)^T \mathcal{G}_i<br>$</p>
<p>旋转不变：<br>$<br>\tilde{\mathcal{D}}_i&#x3D;\left(\mathcal{G}_i\right)^T\left(\mathcal{R}_i U\right)\left(\mathcal{R}_i U\right)^T \mathcal{G}_i&#x3D;\left(\mathcal{G}_i\right)^T \mathcal{R}_i U U^T \mathcal{R}_i \mathcal{G}_i&#x3D;\mathcal{D}_i<br>$</p>
<p>神经网络的构建:<br><img src="/../images/image-20230701144137434.png" alt="figure"></p>
<img src="../images/image-20230701145048547.png" alt="image-20230701145048547" style="zoom:67%;">



<h4 id="数据集构建"><a href="#数据集构建" class="headerlink" title="数据集构建"></a>数据集构建</h4><p><img src="/../images/image-20230701145823815.png" alt="image-20230701145823815"></p>
<p><img src="/../images/image-20230701150019764.png" alt="image-20230701150019764"></p>
<p><img src="/../images/image-20230701150243858.png" alt="image-20230701150243858"></p>
<blockquote>
<p>需要保证，大体系结构中的局部体系的结果都在数据集里面有实现。</p>
</blockquote>
<p><img src="/../images/image-20230701150513105.png" alt="image-20230701150513105"></p>
<h3 id="DeePMD-kit-的代码实现"><a href="#DeePMD-kit-的代码实现" class="headerlink" title="DeePMD-kit 的代码实现"></a>DeePMD-kit 的代码实现</h3><p><strong>代码修改</strong>： DeePMD-kit 的代码实现涉及到几个主要部分，包括<code>trainer</code>，<code>model</code>，<code>embedding net</code> 和 <code>fitting net</code>。<code>trainer</code> 部分解析输入 JSON 文件中的参数。<code>model</code> 部分构建操作图，包括<code>type embed net</code>，<code>embedding net</code> 和 <code>fitting net</code>。<code>embedding net</code> 接收环境矩阵 $ \mathcal{R} $ 作为输入，并输出矩阵 $ \mathcal{G} $。<code>fitting net</code> 接收描述符向量作为输入，并输出能量预测。</p>
<p><strong>模型训练的代码</strong>：</p>
<pre><code class="python">class Trainer () :
    def __init__(self, jdata, run_opt):
        # 初始化函数，设置训练参数和运行选项

    def build (self, stop_batch = 0) :
        # 构建训练模型

    def train (self, 
               stop_batch = 0,
               is_init = True, 
               print_iter = 100, 
               save_iter = 1000, 
               save_ckpt = True) :
        # 训练模型的主要函数
        # stop_batch: 停止训练的批次数
        # is_init: 是否初始化模型
        # print_iter: 打印日志的迭代次数
        # save_iter: 保存模型的迭代次数
        # save_ckpt: 是否保存检查点

    def validate (self, 
                  tr_data, 
                  tr_pref) :
        # 验证模型

    def get_feed_dict (self, 
                       batch,
                       is_training) :
        # 获取训练数据的feed字典

    def print_head (self) :
        # 打印训练信息的头部

    def print_info (self, 
                    cur_batch,
                    time,
                    data) :
        # 打印训练信息
</code></pre>
<h3 id="训练和验证"><a href="#训练和验证" class="headerlink" title="训练和验证"></a>训练和验证</h3><p>使用大量的训练数据（原子配置和相应的能量和力）来训练 DeePMD-kit 模型的神经网络。通过最小化模型预测和实际能量和力之间的差异来调整网络的权重。训练完成后，模型需要使用新数据进行验证，以评估其性能。这涉及将模型在训练期间未见过的原子配置输入，并将模型的预测与实际能量和力进行比较。</p>
<h3 id="模拟"><a href="#模拟" class="headerlink" title="模拟"></a>模拟</h3><p>一旦模型经过训练和验证，它就可以用于分子动力学模拟。这是以 Markdown 格式书写的 DeePMD-kit 的概述。这段内容可以粘贴到 Markdown 编辑器或兼容 Markdown 的平台（如 GitHub、Jupyter Notebook等）中，并会被渲染成结构化的文本，包括标题、列表和图片（请注意，图片URL应该被替换为实际的图片链接）。</p>
<div style="page-break-after: always;">
    <button>你好 </button>
</div>


<div style="page-break-after: always;"></div>

<h2 id="图神经网络在-DeePMD-中的应用"><a href="#图神经网络在-DeePMD-中的应用" class="headerlink" title="图神经网络在 DeePMD 中的应用"></a>图神经网络在 DeePMD 中的应用</h2><p>探讨如何使用图神经网络来改进 DeePMD-kit 的性能和精度。</p>
<div style="page-break-after: always;"></div>

<h2 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h2><p>展示 DeePMD-kit 在实际问题中的应用，如材料科学和生物分子。</p>
<div style="page-break-after: always;"></div>

<h2 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h2><p>评估 DeePMD-kit 的准确性和效率。</p>
<div style="page-break-after: always;"></div>

<h2 id="与其他工具的比较"><a href="#与其他工具的比较" class="headerlink" title="与其他工具的比较"></a>与其他工具的比较</h2><p>将 DeePMD-kit 与其他分子动力学模拟工具进行比较。</p>
<div style="page-break-after: always;"></div>

<h2 id="社区和资源"><a href="#社区和资源" class="headerlink" title="社区和资源"></a>社区和资源</h2><p>介绍 DeePMD-kit 的社区和相关资源，如文档和教程。</p>
<div style="page-break-after: always;"></div>

<h2 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h2><p>探讨 DeePMD-kit 的未来发展方向和潜在改进。</p>
<div style="page-break-after: always;"></div>

<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>总结报告的主要发现和结论。</p>
<div style="page-break-after: always;"></div>

<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>列出用于编写报告的参考文献。</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
    </div>
    <a href="/2023/07/02/DeepMD%E8%AF%A6%E7%BB%86%E5%86%85%E5%AE%B9%E4%BB%8B%E7%BB%8D/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/06/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">
        <h2 class="post-title">深度学习框架</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/6/17
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            
            
        </div>
    </div>
    <div class="post-tags">
        
        
    </div>
    <a href="/2023/06/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/06/15/%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5-%E5%88%86%E5%AD%90%E5%B0%BA%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
        <h2 class="post-title">组会汇报-分子尺度深度学习</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/6/15
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h3 id="基于原子和神经网络方法的精确和高效的过程模拟"><a href="#基于原子和神经网络方法的精确和高效的过程模拟" class="headerlink" title="基于原子和神经网络方法的精确和高效的过程模拟"></a>基于原子和神经网络方法的精确和高效的过程模拟</h3><ul>
<li>作者单位：台积电</li>
</ul>
<blockquote>
<p>这篇论文讨论了一种新的基于机器学习和原子模拟方法的强大研究方法。利用这种方法，作者预测了使用Si2H6（硅烷）前驱体进行硅外延生长的一种先前未被发现的反应序列。这一复杂的表面反应机制通过元动力学模拟揭示出来，它涉及到可控的中间体SiH2的形成过程，解释了在H2载气存在下进行Si2H6吸附时，实验报告中长期未解的生长平台现象。</p>
<p>由于其准确性和灵活的设计，这个工作流模型可以被应用于任何沉积和蚀刻过程条件的优化，以提高薄膜质量，并为下一代电子设备材料提供产量改进的途径。</p>
</blockquote>
<h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p><img src="/../images/image-20230616104936985.png" alt="image-20230616104936985"></p>
<p>利用<code>VASP</code>和<code>DeepMD</code>来构建深度学习， 就是利用前者计算力场，利用后者拟合。</p>
<h4 id="模型训练与验证"><a href="#模型训练与验证" class="headerlink" title="模型训练与验证"></a>模型训练与验证</h4><p><img src="/../images/image-20230616105632564.png" alt="image-20230616105632564"></p>
<ol>
<li><strong>DNN训练数据生成过程</strong></li>
</ol>
<ul>
<li><p>FPMD</p>
<ul>
<li>生成MD轨迹</li>
</ul>
</li>
<li><p>DFT</p>
<ul>
<li>对原子位置和晶格向量进行扰动</li>
</ul>
</li>
<li><p>使用扰动法进行第一个训练周期</p>
</li>
<li><p>主动学习MD方案</p>
<ul>
<li>对大规模、表面和前体吸附配置进行处理</li>
</ul>
</li>
<li><p>验证</p>
<ul>
<li>跟踪训练中的能量和力的误差</li>
<li>对硅的体积电子性质和表面稳定性进行基准测试</li>
</ul>
</li>
</ul>
<ol>
<li><strong>DNN模型基准测试过程</strong></li>
</ol>
<ul>
<li><p>声子特性</p>
<ul>
<li>在声子色散和态密度中捕获关键的声子特性</li>
</ul>
</li>
<li><p>原子位移演化</p>
<ul>
<li>跟踪顶层原子的原子位移</li>
</ul>
</li>
<li><p>表面重构</p>
<ul>
<li>进行表面重构</li>
</ul>
</li>
</ul>
<p>简而言之，利用vasp计算原子模型得到的能量&#x2F;受力，然后拟合这两者关系得到力场。</p>
<p><strong>VASP计算</strong></p>
<p>定义<code>INCAR(定义计算内容， 类似config，计算能量/受力)</code>, <code>POSCAR(给出原子模型)</code>两个文件， 自动生成<code>POTCAR(pseudopotential)</code>， 基于此，进行计算， 结果保存在<code>OUTCAR</code>里面。</p>
<ul>
<li>INCAR</li>
</ul>
<pre><code class="bASH">Collinear Magnetic Calculation
ISPIN      =  2        (Spin polarised DFT)
MAGMOM   =  -4 -4 -4 -4 -4 -4 -4 -4 4 4 4 4 4 4 4 4 4 4 2*4 2*4 2*4 31*0.5         (Set this parameters manually)
LASPH      = .TRUE.    (Non-spherical elements; d/f convergence)
GGA_COMPAT = .FALSE.   (Apply spherical cutoff on gradient field)
VOSKOWN    =  1        (Enhances the magnetic moments and the magnetic energies)
LMAXMIX    =  4        (For d elements increase LMAXMIX to 4, f: LMAXMIX = 6)
AMIX       =  0.2    (Mixing parameter to control SCF convergence)
BMIX       =  0.0001 (Mixing parameter to control SCF convergence)
AMIX_MAG   =  0.4    (Mixing parameter to control SCF convergence)
BMIX_MAG   =  0.0001 (Mixing parameter to control SCF convergence)

 
DFT+U Calculation
LDAU   = .TRUE.        (Activate DFT+U)
LDATYPE=  2            (Dudarev; only U-J matters)
LDAUL  =  2  2  2  2  -1       (Orbitals for each species)
LDAUU  =  4  4  4  4  0       (U for each species)
LDAUJ  =  0.5  0.5  0.5  0.5  0       (J for each species)
LMAXMIX=  4            (Mixing cut-off; 4-d, 6-f)

 
Global Parameters
ISTART =  1            (Read existing wavefunction; if there)
# ISPIN =  2           (Spin polarised DFT)
# ICHARG =  11         (Non-self-consistent: GGA/LDA band structures)
LREAL  = Auto          (Projection operators: automatic)
ENCUT  =  600        (Cut-off energy for plane wave basis set, in eV)
PREC   =  Normal       (Precision level)
LWAVE  = .TRUE.        (Write WAVECAR or not)
LCHARG = .TRUE.        (Write CHGCAR or not)
ADDGRID= .TRUE.        (Increase grid; helps GGA convergence)
# LVTOT  = .TRUE.      (Write total electrostatic potential into LOCPOT or not)
# LVHAR  = .TRUE.      (Write ionic + Hartree electrostatic potential into LOCPOT or not)
# NELECT =             (No. of electrons: charged cells; be careful)
# LPLANE = .TRUE.      (Real space distribution; supercells)
# NPAR   = 4           (Max is no. nodes; don&#39;t set for hybrids)
# NWRITE = 2           (Medium-level output)
# KPAR   = 2           (Divides k-grid into separate groups)
# NGX    = 500         (FFT grid mesh density for nice charge/potential plots)
# NGY    = 500         (FFT grid mesh density for nice charge/potential plots)
# NGZ    = 500         (FFT grid mesh density for nice charge/potential plots)

Electronic Relaxation
ISMEAR =  0            (Gaussian smearing; metals:1)
SIGMA  =  0.05         (Smearing value in eV; metals:0.2)
NELM   =  200           (Max electronic SCF steps)
#NELMIN =  6            (Min electronic SCF steps)
EDIFF  =  1E-04        (SCF energy convergence; in eV)
# GGA  =  PS           (PBEsol exchange-correlation)

Ionic Relaxation
NSW    =  200          (Max ionic steps)
IBRION =  2            (Algorithm: 0-MD; 1-Quasi-New; 2-CG)
ISIF   =  2            (Stress/relaxation: 2-Ions, 3-Shape/Ions/V, 4-Shape/Ions)
EDIFFG = -5E-02        (Ionic convergence; eV/AA)

Other Sets
#ISYM = 0
LORIBT = 11
LREAL = auto
LDIPOL = .TRUE.
IDIPOL = 3 
</code></pre>
<ul>
<li>POSCAR</li>
</ul>
<pre><code class="bash"> result1\(-1\0\0)\(2)                   
   1.00000000000000     
     8.4650001526000000    0.0000000000000000    0.0000000000000000
     0.0000000000000000    8.4650001526000000    0.0000000000000000
     0.0000000000000000    0.0000000000000000   22.4559993744000010
   Fe   Mn   Co   Ni   O 
    18     2     2     2    31
Selective dynamics
Direct
      0.91149922       0.93394451       0.30298449   T  T  T 
      0.54928124       0.56044684       0.29732690   T  T  T 
      0.00078665       0.50685843       0.14280074   T  T  T 
      0.50100867      -0.00087781       0.14336777   T  T  T 
      0.74966002       0.24499001       0.04966000   F  F  F 
      0.25306246       0.24622419       0.24308685   T  T  T 
      0.75646493       0.73886826       0.23682094   T  T  T 
      0.24959000       0.74254000       0.04955000   F  F  F 
      0.36362551       0.88939961       0.28422896   T  T  T 
      0.37275001       0.37446999       0.09679000   F  F  F 
      0.62655997       0.87489003       0.00145000   F  F  F 
      0.88892126       0.37871634       0.27967138   T  T  T 
      0.12474000       0.37724000       0.00286000   F  F  F 
      0.13537451       0.87019407       0.19315328   T  T  T 
      0.87775999       0.87234002       0.09593000   F  F  F 
      0.61822538       0.36499678       0.19073725   T  T  T 
      0.37485999       0.12455000       0.00229000   F  F  F 
      0.12609001       0.12396000       0.09679000   F  F  F 
      0.87503127       0.12539944       0.19149679   T  T  T 
      0.62344003       0.62557000       0.09738000   F  F  F 
      0.87712997       0.62597001       0.00195000   F  F  F 
      0.61720147       0.11961980       0.28503860   T  T  T 
      0.36775063       0.62527783       0.19060239   T  T  T 
      0.11978615       0.61702653       0.28201958   T  T  T 
      0.38083549       0.37785134       0.19095691   T  T  T 
      0.88235998       0.11405000       0.09627000   F  F  F 
      0.66019525       0.87924509       0.29268959   T  T  T 
      0.12107000       0.61469001       0.00023000   F  F  F 
      0.35538812       0.65701680       0.28963690   T  T  T 
      0.86782998       0.87575001       0.00517000   F  F  F 
      0.13143000       0.37704000       0.09430000   F  F  F 
      0.62352750       0.13241024       0.19208011   T  T  T 
      0.36914000       0.13489001       0.09718000   F  F  F 
      0.12902930       0.63325776       0.19266269   T  T  T 
      0.87686175       0.60810064       0.28978881   T  T  T 
      0.11830000       0.87140000       0.09951000   F  F  F 
      0.61862999       0.11504000       0.00147000   F  F  F 
      0.88683371       0.87465383       0.18953353   T  T  T 
      0.37419000       0.61343998       0.09935000   F  F  F 
      0.11465552       0.38072686       0.28473890   T  T  T 
      0.85682220       0.15173567       0.29227789   T  T  T 
      0.36780000       0.37867001       0.00566000   F  F  F 
      0.63459998       0.87900001       0.09384000   F  F  F 
      0.87550002       0.63556999       0.09510000   F  F  F 
      0.11433896       0.85777596       0.28410816   T  T  T 
      0.38352337       0.11589898       0.28979767   T  T  T 
      0.61631000       0.37123001       0.10025000   F  F  F 
      0.88268000       0.37531999       0.00032000   F  F  F 
      0.61149357       0.60937161       0.19422251   T  T  T 
      0.36969135       0.86804908       0.18981720   T  T  T 
      0.13167000       0.13587000       0.00198000   F  F  F 
      0.63001001       0.63647002       0.00231000   F  F  F 
      0.12931348       0.11474703       0.18829403   T  T  T 
      0.38371000       0.87102997       0.00000000   F  F  F 
      0.86592531       0.37820479       0.19126102   T  T  T 
</code></pre>
<p><img src="/../images/image-20230616111122830.png" alt="image-20230616111122830"></p>
<p><strong>DeepMD计算</strong></p>
<ul>
<li>原理</li>
<li>原子的能量可以有临近的环境决定(截断半径$R_c$的大小。)</li>
</ul>
<p>$$<br>E &#x3D; \sum_{i} E_{i}<br>$$</p>
<ul>
<li>$E_i$ 的构建步骤：</li>
</ul>
<ol>
<li>首先构造一个新的坐标系用于保持环境的平移、旋转和置换对称：</li>
</ol>
<p><img src="/../images/image-20230617144548185.png" alt="image-20230617144548185"></p>
<ol start="2">
<li>新坐标系的$D_{ij}$ 作为DNN神经网络的输入用于求解$E_i$, 这里采用的是<code>MLP</code>神经网络</li>
</ol>
<p><img src="/../images/image-20230617144909939.png" alt="image-20230617144909939"></p>
<ol start="3">
<li>基于<code>Adam</code>优化算法来进行优化， 定义损失函数如下：</li>
</ol>
<p>$$<br>L\left(p_\epsilon, p_f, p_{\xi}\right)&#x3D;p_\epsilon \Delta \epsilon^2+\frac{p_f}{3 N} \sum_i\left|\Delta \boldsymbol{F}<em>i\right|^2+\frac{p</em>{\xi}}{9}|\Delta \xi|^2<br>$$</p>
<blockquote>
<p>$\Delta$：这个表示DPMD（Deep Potential Molecular Dynamics）预测与训练数据之间的差异。这个差异可能会被用来计算模型的损失函数，以便在训练过程中调整模型的参数。</p>
<p>$N$：这个表示原子的数量。在物理和化学的模拟中，这个参数通常用来表示系统的大小或复杂性。</p>
<p>$\epsilon$：这个表示每个原子的能量。在物理和化学的模拟中，这个参数通常用来表示系统的总能量或者能量分布。</p>
<p>$\boldsymbol{F}_i$：这个表示作用在第$i$个原子上的力。在分子动力学模拟中，这个参数通常用来计算原子的运动。</p>
<p>$\xi$：这个表示单位原子的”virial tensor”（或称为”维里张量”），它定义为$\Xi&#x3D;-\frac{1}{2} \sum_i \boldsymbol{R}_i \otimes \boldsymbol{F}_i$，然后除以原子的数量$N$。维里张量是一个描述系统压力和体积变化关系的物理量。</p>
<p>$p_\epsilon, p_f$, 和 $p_{\xi}$：这些是可调的预因子（prefactors），它们可以在训练过程中调整，以达到最小化损失函数的目标。当数据中缺少virial信息时，我们设定$p_{\xi}&#x3D;0$。在训练过程中，我们逐渐增大$p_\epsilon$和$p_{\xi}$，同时减小$p_f$，以确保在训练开始时，力的项占主导，而在训练结束时，能量和virial项变得重要。</p>
</blockquote>
<p>基于前面<code>VASP</code> 计算得到的数据，便可以开始训练力场了。</p>
<p><img src="/../images/image-20230616115654284.png" alt="image-20230616115654284"></p>
<p>之前配置的内容：</p>
<pre><code class="python">&#123;
    &quot;model&quot;: &#123;
        &quot;type_map&quot;:                [&quot;Ca&quot;,&quot;Si&quot;,&quot;O&quot;,&quot;H&quot;],
        &quot;descriptor&quot; :&#123;
            &quot;type&quot;:                &quot;se_a&quot;,
            &quot;sel&quot;:                 [30,30,90,70],
            &quot;rcut_smth&quot;:           6.80,
            &quot;rcut&quot;:                7.00,
            &quot;neuron&quot;:              [25, 50, 100],
            &quot;resnet_dt&quot;:           false,
            &quot;axis_neuron&quot;:         16,
            &quot;seed&quot;:                1
        &#125;,
        &quot;fitting_net&quot; : &#123;
            &quot;neuron&quot;:              [40,40,40],
            &quot;resnet_dt&quot;:           true,
            &quot;coord_norm&quot;:          true,
            &quot;type_fitting_net&quot;:    false,
            &quot;seed&quot;:                1
        &#125;
    &#125;,
    &quot;loss&quot;: &#123;
        &quot;start_pref_e&quot;:            0.02,
        &quot;limit_pref_e&quot;:            1,
        &quot;start_pref_f&quot;:            1000,
        &quot;limit_pref_f&quot;:            1,
        &quot;start_pref_v&quot;:            0,
        &quot;limit_pref_v&quot;:            0
    &#125;,
    &quot;learning_rate&quot;: &#123;
        &quot;type&quot;:                    &quot;exp&quot;,
        &quot;decay_steps&quot;:             5000,
        &quot;start_lr&quot;:                0.001,
        &quot;stop_lr&quot;:                 3.51e-9
    &#125;,
    &quot;training&quot;: &#123;
        &quot;systems&quot;:                 [数据集路径],
        &quot;set_prefix&quot;:              &quot;set&quot;,
        &quot;stop_batch&quot;:              500000,
        &quot;batch_size&quot;:              1,
        &quot;seed&quot;:                    1,
        &quot;_comment&quot;:                &quot;frequencies counted in batch&quot;,
        &quot;disp_file&quot;:               &quot;lcurve.out&quot;,
        &quot;disp_freq&quot;:               100,
        &quot;numb_test&quot;:               50,
        &quot;save_freq&quot;:               1000,
        &quot;save_ckpt&quot;:               &quot;model.ckpt&quot;,
        &quot;load_ckpt&quot;:               &quot;model.ckpt&quot;,
        &quot;disp_training&quot;:           true,
        &quot;time_training&quot;:           true,
        &quot;profiling&quot;:               false,
        &quot;profiling_file&quot;:          &quot;timeline.json&quot;
    &#125;
&#125;
</code></pre>
<p>![320_320_320_lcurve](F:&#x2F;深度势能&#x2F;fitting Network&#x2F;all_lcurve_data&#x2F;320_320_320_lcurve.jpg)</p>
<p>![神经元与训练误差的关系](F:&#x2F;深度势能&#x2F;fitting Network&#x2F;all_lcurve_data&#x2F;神经元与训练误差的关系.png)</p>
<h4 id="结果讨论"><a href="#结果讨论" class="headerlink" title="结果讨论"></a>结果讨论</h4><ul>
<li>SiH$_4$和Si$_2$H$_6$吸附的反应动力学。</li>
</ul>
<p><img src="/../images/image-20230616111449593.png" alt="image-20230616111449593"></p>
<ol>
<li><strong>自由能表面（FES）计算</strong>：该表面描述了化学反应的空间。它是通过使用元动力学模拟和增强采样方法来计算的。元动力学模拟是一种计算方法，可以帮助研究者对复杂系统的自由能表面进行建模和分析。</li>
<li><strong>高斯山（Gaussian hills）</strong>：整个势能表面是通过随机添加潜在能量（“高斯山”）来采样的。高斯山是元动力学模拟中的一个重要概念，用于改变势能表面，以提高探索率并避免陷入局部最小值。</li>
<li><strong>集体变量（CVs）选择</strong>：选择集体变量是一个关键的决策步骤，它需要确保对整个前体吸附过程的准确和有效的物理预测。集体变量是元动力学模拟中的一个重要概念，它表示系统中重要的、可变的参数。</li>
<li><strong>SiH4吸附</strong>：文本描述了SiH4吸附过程中的关键反应中间体和激活能。这些结果与之前的模拟结果相符。</li>
<li><strong>Si2H6吸附</strong>：在温度低于700K时，Si2H6吸附的速率限制步骤是第一个反应*H + Si2H5，其中一个氢被转移到表面，激活能为0.34 eV。</li>
<li><strong>Si2H6气相分解</strong>：在温度高于700K时，Si2H6的分解过程包括生成SiH2和SiH4的中间产品以及Si2H4和H2气体，它们的激活能都约为2 eV。实验表明，SiH2产品容易在36.5 Torr和720 K的条件下在表面上吸附。</li>
</ol>
<h3 id="硅生长的新反应机制揭示"><a href="#硅生长的新反应机制揭示" class="headerlink" title="硅生长的新反应机制揭示"></a>硅生长的新反应机制揭示</h3><p><strong>氢脱附的可能的其他的反应途径</strong></p>
<ul>
<li><strong>氢解吸的替代反应路径</strong>：这个替代反应路径在图10中以示意图的形式描绘。解吸是吸附过程的逆过程，也就是说，吸附到物质表面的粒子离开表面并回到气相。</li>
</ul>
<p><img src="/../images/image-20230616112412823.png" alt="image-20230616112412823"></p>
<ul>
<li><strong>文献中的氢解吸路径</strong>：通常文献中讨论的氢解吸路径涉及到两个表面氢（surface H）。表面氢是指已经吸附在物质表面上的氢原子。</li>
<li><strong>表面氢和前驱体氢的相互作用</strong>：然而，表面氢与前驱体氢的相互作用产生了更低的活化能。这个过程在图11中展示。活化能是一种反应需要的能量，更低的活化能意味着反应更容易进行。</li>
</ul>
<p><img src="/../images/image-20230616112437013.png" alt="image-20230616112437013"></p>
<ul>
<li><strong>影响因素</strong>：当前驱体或载气流量增加时，这个具有较低活化能的过程可能更容易发生。这意味着，通过改变前驱体或载气的流量，可以影响这个反应过程。</li>
</ul>
<p>分解产物SiH2的吸附</p>
<ol>
<li><strong>SiH2的吸附</strong>：通过DPMD研究预测，SiH2可以在无阻力的过程中自发地吸附在Si表面（图9，公式4）。当活化能Ea&#x3D; 0 eV时，根据阿伦尼乌斯方程，SiH2在大于700 K的温度范围内的吸附速度是常数，这导致生长速率呈现出一个平台阶段。</li>
</ol>
<p><img src="/../images/image-20230616113051079.png" alt="image-20230616113051079"></p>
<ol>
<li><strong>Si的生长过程</strong>：为了全面了解从低温到高温的Si生长过程，计算了所有可能的表面反应作为表面氢覆盖率的函数（图11）。反应速率在SiH4、Si2H6和SiH2吸附，H2吸附和所有已知H解吸路径中被提取出来（图12）。由于SiH2的吸附没有活化障碍，其数据被放置在水平轴上。</li>
</ol>
<p><img src="/../images/image-20230616113136130.png" alt="image-20230616113136130"></p>
<ol>
<li><strong>Si生长的模拟</strong>：模拟了通过Si2H6沉积生长Si的过程，这也支持了之前提出的在低温和高温区间存在明显分界线的观点（图13）。在低温区，根据图11和图12，H的解吸被证实为速率限制步骤。当温度适度增加时，H表面覆盖率略有降低，而可供前驱体吸附的Si表面积增加，因此Si的生长速率随温度的升高而增加。</li>
</ol>
<p><img src="/../images/image-20230616113146211.png" alt="image-20230616113146211"></p>
<ol>
<li><strong>高温区的特性</strong>：在约700 K，Si2H6在气相中开始分解，生成SiH2和SiH4。因为SiH2在Si表面的吸附是无阻力的过程，所以它在中温和高温区域占主导，引起了生长速率的“恒定”并定义了低温和高温机制之间的“交叉点”（图13）。此外，SiH2吸附产生表面SiH键，SiH（0.7 eV）或H（0.5 eV）的小表面扩散障碍在大于700 K可热力学上实现，促进了表面重排和加速了H2的解吸（图14）。</li>
</ol>
<p><img src="/../images/image-20230616113202942.png" alt="image-20230616113202942"></p>
<ol>
<li><strong>更高温度下的行为</strong>：在大约840 K的高温开始，表面H覆盖率显著降低，任何前驱体或产品（SiH4，Si2H6，或SiH2）都可以直接在表面沉积，直到约1100 K生长速率“饱和”，系统进入由前驱体流速限制的阶段。</li>
</ol>
<h4 id="总体研究步骤"><a href="#总体研究步骤" class="headerlink" title="总体研究步骤"></a>总体研究步骤</h4><ol>
<li><p><strong>建立反应模型</strong>：研究者首先定义了一个包含SiH4等分子的系统。这个系统可能包括了所有可能的反应参与者和环境条件。</p>
</li>
<li><p><strong>拟合势能面</strong>：DeepMD是一种基于深度学习的势能面拟合方法。这个模型使用一组从量子力学计算得到的数据作为训练集，这些数据可能包括原子间的距离、角度、能量等信息。DeepMD模型通过训练学习这些数据的特征，拟合出整个反应系统的势能面。在拟合过程中，DeepMD模型能够学习到各种原子间的相互作用，从而精确地模拟复杂的反应过程。</p>
</li>
<li><p><strong>搜索反应路径</strong>：在得到势能面后，研究者就可以在这个势能面上搜索反应路径。这通常是通过启动分子动力学模拟来完成的。模拟过程中，系统会在势能面上进行演化，寻找从反应物到产物的最低能量路径。这个过程可以揭示反应的过渡态（Transition State），也就是反应路径上的能量最大点。</p>
<ul>
<li><p><strong>力场（势能面）的建立</strong>：在量子力学级别上进行高精度的力场参数化，使用深度学习算法（如DeepMD）训练并拟合出描述分子内部和分子间相互作用的势能面。这个过程需要大量的量子力学计算数据，包括不同原子构型下的能量、力等。经过训练，DeepMD模型将能够对新的原子构型给出相应的势能和力的预测。</p>
</li>
<li><p><strong>分子动力学模拟</strong>：利用上一步拟合得到的势能面（力场），进行分子动力学模拟。这个过程中，分子在力场的驱动下进行运动，经过一段时间后，可以获得反应的动态过程。通过分析模拟得到的轨迹，可以找到反应的过渡态、中间产物，以及反应速率等信息，从而揭示反应的详细机理。</p>
</li>
</ul>
</li>
<li><p><strong>揭示反应机理</strong>：通过对反应路径的分析，研究者可以揭示反应的详细机理。这可能包括反应的中间态、过渡态以及反应的速率常数等信息。例如，SiH4分子在反应过程中可能会经历一系列的断裂和形成，通过分析这些信息，研究者可以得出SiH4分子在反应过程中的详细行为，从而了解其反应机理。</p>
</li>
</ol>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/%E5%88%86%E5%AD%90%E5%B0%BA%E5%BA%A6%EF%BC%8C-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="color: #ffa2c4">分子尺度， 深度学习</a>
        </span>
        
    </div>
    <a href="/2023/06/15/%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5-%E5%88%86%E5%AD%90%E5%B0%BA%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/06/10/%E5%9F%BA%E4%BA%8EGPTPlus%E8%B4%A6%E5%8F%B7%E9%83%A8%E7%BD%B2API/">
        <h2 class="post-title">基于GPTPlus账号部署API</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/6/10
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <blockquote>
<p>这个博客主要介绍如何基于<code>GPT - Plus</code>用户的账号来部署<code>API</code>。</p>
</blockquote>
<p>整个项目是对<a target="_blank" rel="noopener" href="https://github.com/linkedlist771/infiniteGPT4">linkedlist771&#x2F;infiniteGPT4: 基于revChatGPT和IOS新推出的无限次GPT4使用实现GPT4无限次数使用的API (github.com)</a> 的一个延伸， 在之前的项目中没有解决很重要的问题， 就是反代服务器利用的是作者部署的公网服务器。如果要自己使用的话，最好能够基于自己的服务器实现一个。所以第一步我们需要构建一个反代服务。</p>
<h3 id="ChatGPT反代服务构建"><a href="#ChatGPT反代服务构建" class="headerlink" title="ChatGPT反代服务构建"></a>ChatGPT反代服务构建</h3><p>反代服务器的搭建，可以参考：<a target="_blank" rel="noopener" href="https://github.com/acheong08/ChatGPT-Proxy-V4">acheong08&#x2F;ChatGPT-Proxy-V4: Simple Cloudflare bypass for ChatGPT (github.com)</a>。 </p>
<p>首先需要下载这个项目：</p>
<pre><code class="bash">git clone git@github.com:acheong08/ChatGPT-Proxy-V4.git
</code></pre>
<p>笔者使用的服务器为<code>centos</code>， 基于你使用的服务器的类型，不同的命令可能稍有不同，稍作调整即可。主要分为以下几步:</p>
<ol>
<li><strong>安装Go环境：</strong></li>
</ol>
<p>Go的安装包可以从<a target="_blank" rel="noopener" href="https://golang.org/dl/">Go官网</a>上找到，选择一个合适的版本下载到你的CentOS服务器。例如，如果我们要下载Go 1.16.4版本，可以使用下面的命令：</p>
<pre><code class="bash">
wget https://golang.org/dl/go1.16.4.linux-amd64.tar.gz
</code></pre>
<p>然后，解压这个文件到<code>/usr/local</code>：</p>
<pre><code class="bash">tar -C /usr/local -xzf go1.16.4.linux-amd64.tar.gz
</code></pre>
<p>将Go的二进制文件添加到<code>PATH</code>中：</p>
<pre><code class="bash">echo &quot;export PATH=$PATH:/usr/local/go/bin&quot; &gt;&gt; ~/.bash_profile
source ~/.bash_profile
</code></pre>
<p>你可以使用<code>go version</code>命令来验证Go是否安装成功。</p>
<p> <img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230610174001359.png" alt="image-20230610174001359"></p>
<p>我这里测试是成功的。</p>
<ol start="2">
<li><strong>设置环境变量：</strong></li>
</ol>
<p>你需要一个ChatGPT Plus账号的PUID来设置环境变量。你可以使用下面的命令将PUID添加到环境变量中：</p>
<pre><code>bashCopy codeecho &quot;export PUID=\&quot;user-...\&quot;&quot; &gt;&gt; ~/.bash_profile
source ~/.bash_profile
</code></pre>
<p>记得将”user-…”替换为你的实际PUID。</p>
<p>其中<code>PUID</code>意思为<code>Plus UID</code> 也就是你的账户的ID， 可以在这里找到：<a target="_blank" rel="noopener" href="https://chat.openai.com/api/auth/session">chat.openai.com&#x2F;api&#x2F;auth&#x2F;session</a>， </p>
<ol start="3">
<li><strong>构建和运行项目：</strong></li>
</ol>
<p>首先，你需要把项目代码复制到你的服务器上。你可以使用<code>git clone</code>命令来完成这个步骤，如果项目代码托管在一个git仓库上的话。</p>
<p>在项目的根目录下，使用<code>go build</code>命令构建项目：</p>
<pre><code class="bash">go build
</code></pre>
<p>将会输出一下内容：</p>
<pre><code class="bash">go build
go: downloading github.com/acheong08/endless v0.0.0-20230522010333-1359fd84c836
go: downloading github.com/bogdanfinn/fhttp v0.5.22
go: downloading github.com/bogdanfinn/tls-client v1.3.12
go: downloading github.com/gin-gonic/gin v1.9.0
go: downloading github.com/andybalholm/brotli v1.0.5
go: downloading github.com/bogdanfinn/utls v1.5.16
go: downloading golang.org/x/net v0.10.0
go: downloading github.com/tam7t/hpkp v0.0.0-20160821193359-2b70b4024ed5
go: downloading github.com/gin-contrib/sse v0.1.0
go: downloading github.com/mattn/go-isatty v0.0.19
go: downloading github.com/klauspost/compress v1.16.5
go: downloading golang.org/x/crypto v0.9.0
go: downloading golang.org/x/text v0.9.0
go: downloading github.com/go-playground/validator/v10 v10.14.0
go: downloading github.com/pelletier/go-toml/v2 v2.0.8
go: downloading github.com/ugorji/go/codec v1.2.11
go: downloading google.golang.org/protobuf v1.30.0
go: downloading gopkg.in/yaml.v3 v3.0.1
go: downloading golang.org/x/sys v0.8.0
go: downloading github.com/gabriel-vasile/mimetype v1.4.2
go: downloading github.com/go-playground/universal-translator v0.18.1
go: downloading github.com/leodido/go-urn v1.2.4
...
</code></pre>
<p>现在，你应该可以在项目的根目录下看到一个叫做<code>ChatGPT-Proxy-V4</code>的可执行文件。你可以直接运行这个文件来启动项目：</p>
<p>这是我的目录：</p>
<pre><code class="bash">ChatGPT-Proxy-V4  docker-compose.yml  Dockerfile  go1.20.5.linux-amd64.tar.gz  go.mod  go.sum  LICENSE  main.go  README.md
</code></pre>
<p>运行后， 你讲看到以下输出：</p>
<pre><code class="bash">[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production.
 - using env:   export GIN_MODE=release
 - using code:  gin.SetMode(gin.ReleaseMode)

[GIN-debug] GET    /ping                     --&gt; main.main.func1 (3 handlers)
[GIN-debug] PATCH  /admin/puid               --&gt; main.main.func2 (4 handlers)
[GIN-debug] PATCH  /admin/password           --&gt; main.main.func3 (4 handlers)
[GIN-debug] GET    /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] POST   /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] PUT    /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] PATCH  /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] HEAD   /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] OPTIONS /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] DELETE /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] CONNECT /api/*path                --&gt; main.proxy (3 handlers)
[GIN-debug] TRACE  /api/*path                --&gt; main.proxy (3 handlers)
2023/06/10 05:54:46 1878014 :9090
</code></pre>
<p>目前，我们就部署完毕了。 注意，这里你需要打开<code>9090</code>端口的防火墙，不然的话反代无法发挥作用。</p>
<pre><code class="bash">sudo firewall-cmd --permanent --add-port=9090/tcp
sudo firewall-cmd --reload
</code></pre>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/GPTPlus-GPT4-API%E9%83%A8%E7%BD%B2/" style="color: #ff7d73">GPTPlus, GPT4 API部署</a>
        </span>
        
    </div>
    <a href="/2023/06/10/%E5%9F%BA%E4%BA%8EGPTPlus%E8%B4%A6%E5%8F%B7%E9%83%A8%E7%BD%B2API/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/06/06/%E7%89%88%E5%9B%BE%E8%AE%BE%E8%AE%A1%E4%BB%8B%E7%BB%8D/">
        <h2 class="post-title">版图设计介绍</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/6/6
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h3 id="版图介绍"><a href="#版图介绍" class="headerlink" title="版图介绍"></a>版图介绍</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1ed0ZL_Eg58">视频来源介绍</a></p>
</blockquote>
<p>版图(lay out)， 定义了在制造中的掩膜的几何图形。多层次的一个绘制， 因为每一张mask都对应一张layout。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230606232859683.png" alt="image-20230606232859683"></p>
<p>不同的颜色代表不同的层次， foundry(代工厂)， 不同的层次是不同的掩膜版，对于芯片的每一个层，对应一个版图。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230606232829685.png" alt="image-20230606232829685"></p>
<p>数字电路的版图主要是影响速度（降低延时和面积）， 模拟版图主要影响速度和精度，（对称性，器件匹配，降低寄生， 避免串扰，优化互联线，看起来好看）。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230606234139272.png" alt="image-20230606234139272"></p>
<p>数字版图杂乱无章， 最小化面积。 </p>
<h3 id="Tapeout-Flow-流片"><a href="#Tapeout-Flow-流片" class="headerlink" title="Tapeout Flow(流片)"></a>Tapeout Flow(流片)</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230606234543501.png" alt="image-20230606234543501"></p>
<p>两者交互利用的是<code>GDSII</code>文件，  </p>
<ul>
<li><code>OPC</code>(optical proximity correction， 光学邻近矫正)</li>
</ul>
<p>掩膜版的图案都是很小的， 来加工<code>wafer</code>（晶圆上的图像）， 由于衍射和光学系统的问题， 通过掩膜版去光刻， </p>
<p>会导致<code>光刻胶的图形和掩膜版并不是完全一致的</code> ， 然后通过其他工艺将光刻胶图像转移到wafer上。</p>
<p><em>Design Pattern</em> -&gt; <em>光刻胶的图形</em></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230606235916759.png" alt="image-20230606235916759"></p>
<p>如果进行OPC矫正后：</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607000141480.png" alt="image-20230607000141480"></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607000150023.png" alt="image-20230607000150023"></p>
<ul>
<li>数字芯片电路设计流程</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607000330248.png" alt="image-20230607000330248"></p>
<ul>
<li><ul>
<li>Logic Design -&gt; Verilog描述</li>
<li>Logic Synthesis -&gt; 构建门级网表</li>
<li>Floorplan -&gt; 布局</li>
<li>Place &amp; Route Tools -&gt; 构建版图雏形（布局布线）</li>
<li>生成GDSII（添加Digital Libraries）</li>
<li>DRC + LVS 检查</li>
<li>Final GDSII</li>
</ul>
</li>
<li><p>模拟集成电路设计流程</p>
</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607001029421.png" alt="image-20230607001029421"></p>
<ul>
<li><ul>
<li>Circuit Design ： 用基本元器件实现。</li>
<li>Simulation ： 频域仿真&#x2F;时域仿真</li>
<li>Layout ： 手工绘制模拟电路版图</li>
<li>DRC LVS 检测： 设计是否满足foundry要求， 检测器件链接关系是否一直</li>
<li>Parasitic Extraction ： 寄生参数提取 -&gt; 生成新的netlist -&gt; post simulation（后仿真）</li>
</ul>
</li>
</ul>
<p><strong>Layout不是绘制图形，更重要的是前期的规划。</strong></p>
<ul>
<li><p>CMOS 晶体管参数：</p>
</li>
<li><ul>
<li><code>Finger</code>：让器件的源极和漏级交叉出现， 截成几段就是几个<code>Finger</code>， 下面的是3(3个蓝色)。</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607175254574.png" alt="image-20230607175254574"></p>
</li>
<li><ul>
<li><code>Multiplier</code>：复制几倍</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607175412729.png" alt="image-20230607175412729"></p>
</li>
<li><ul>
<li><code>W</code>:宽度， <code>L</code> ：长度</li>
</ul>
</li>
</ul>
<p>总的宽长比计算公式：</p>
<p>$Total \quad W&#x2F;L &#x3D; W&#x2F;L \times Finger \times Multiplier$</p>
<h3 id="IC的横截面"><a href="#IC的横截面" class="headerlink" title="IC的横截面"></a>IC的横截面</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607175752145.png" alt="image-20230607175752145"></p>
<p><code>1P4M</code> ： 1 poly 4 metal ，一层多晶硅， 四层金属。 </p>
<p><code>ACT(active)</code> ： 衬底，有源区。</p>
<p><code>CT(contact)</code>： 接触孔， 有源区和M1的通孔</p>
<p><code>M1,M2,M3,M4</code>: 金属</p>
<p><code>MT(metal TOP)</code>: 最上层金属</p>
<p><code>180nm</code>： 指的是，晶体管的最小沟道长度是<code>180nm</code>。</p>
<p>M金属之间是由介质隔离的，  绝缘， 连接金属使用<code>Via(通孔)</code>， 链接M1和M2是<code>Via1</code>。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607180242248.png" alt="image-20230607180242248"></p>
<p><strong>两个金属线之间是存在寄生电容的。</strong></p>
<h3 id="CMOS制备流程图："><a href="#CMOS制备流程图：" class="headerlink" title="CMOS制备流程图："></a>CMOS制备流程图：</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607180600966.png" alt="image-20230607180600966"></p>
<p><code>1:Grow field oxide</code>： 生长场氧， 作用是器件隔离，$0.35\mu m$ 工艺以上用的。 $0.35\mu m$ 工艺以下用 <code>STI</code>隔离。</p>
<p><code>2： </code> 刻蚀</p>
<p><code>3:注入N井</code></p>
<p><code>4:再刻蚀得到的就是active区域。</code></p>
<p><code>5：生成栅氧</code></p>
<p><code>6：沉淀郭金贵。</code></p>
<p><code>7:刻蚀</code></p>
<p><code>8：注入</code></p>
<p><code>9:生长氮化物</code>……..</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607181030747.png" alt="image-20230607181030747"></p>
<p><code>Mask</code>的组成主要是金属（Cr）和 和玻璃（透光的）， 将Cr镀在玻璃上， 金属上有各种图像(Layout定义的)。 </p>
<p><code>Clear Tone</code>： 大部分区域是被涂上金属的， 只有少部分是镂空的， 这样的掩膜版叫做<code>暗场</code>。 地下的红色的就是光刻胶， 是在wafer上面的。</p>
<p>Layout上定义的是镂空的。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607181823904.png" alt="image-20230607181823904"></p>
<p><code>正胶</code>： 有光照的地方会变性，用显影液可以去掉。 <strong>挖空挖洞的一般都是clear tone</strong></p>
<p><code>Dark Tone</code>: 亮场，大部分地方没有金属，只有少部分地方有金属， <strong>要保留的就是dark tone</strong></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607182220028.png" alt="image-20230607182220028"></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607182641437.png" alt="image-20230607182641437"></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607182857765.png" alt="image-20230607182857765"></p>
<p>N井注入，开个孔，进行注入。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607182954092.png" alt="image-20230607182954092"></p>
<p>形成一个N井的区域。 先光刻刻蚀掉光刻胶，再刻蚀氧化硅（可能用HF刻蚀）， 再沉积金属坞。 最后得到的效果</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607183855256.png" alt="image-20230607183855256"></p>
<h3 id="Design-Rules"><a href="#Design-Rules" class="headerlink" title="Design Rules"></a>Design Rules</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607184358426.png" alt="image-20230607184358426"></p>
<p><code>width</code>：<strong>至少是这个值</strong></p>
<p><code>size</code>的形状， 一定是正方形， 表示的是正方形的边长。 <strong>要是这个值</strong></p>
<p><code>enclosure</code>： A包含B， 包裹的距离是<code>enclosure </code></p>
<p><code>extension</code> ： 有一个边超过就行了。</p>
<p><code>overlap</code>： 重叠，两个图像的重叠。</p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607185012751.png" alt="image-20230607185012751"></p>
<h3 id="DRC-Design-Rule-Check"><a href="#DRC-Design-Rule-Check" class="headerlink" title="DRC:(Design Rule Check)"></a>DRC:(Design Rule Check)</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607185325355.png" alt="image-20230607185325355"></p>
<h3 id="LVS-Layout-Versus-Schematic"><a href="#LVS-Layout-Versus-Schematic" class="headerlink" title="LVS:(Layout Versus Schematic)"></a>LVS:(Layout Versus Schematic)</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607185545088.png" alt="image-20230607185545088"></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607185750166.png" alt="image-20230607185750166"></p>
<h2 id="后仿真："><a href="#后仿真：" class="headerlink" title="后仿真："></a>后仿真：</h2><h3 id="寄生参数抽取："><a href="#寄生参数抽取：" class="headerlink" title="寄生参数抽取："></a>寄生参数抽取：</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607185941176.png" alt="image-20230607185941176"></p>
<h3 id="Layout-里面常用的工具："><a href="#Layout-里面常用的工具：" class="headerlink" title="Layout 里面常用的工具："></a>Layout 里面常用的工具：</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607190219993.png" alt="image-20230607190219993"></p>
<p><strong>启动Calibre WorkBench进行LTO</strong>：</p>
<pre><code class="bash">calibrewb
</code></pre>
<h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230614211959737.png" alt="image-20230614211959737"></p>
<ul>
<li>分别选择<code>LEF</code>和<code>DEF</code>文件即可</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230614212030241.png" alt="image-20230614212030241"></p>
<h3 id="存在的问题："><a href="#存在的问题：" class="headerlink" title="存在的问题："></a>存在的问题：</h3><ul>
<li>问题1： 不知道OPC模拟的参数设置（现在采用的是默认的OPC参数设置， 关于模型参数， 迭代次数）：</li>
<li><ul>
<li>原始的版图</li>
</ul>
</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607203724041.png" alt="image-20230607203724041"></p>
<ul>
<li><ul>
<li>OPC矫正后的版图：</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607203829141.png" alt="image-20230607203829141"></p>
</li>
<li><p>问题2： 不知道对于这个版图文件进行OPC光刻矫正是怎么操作，是对每一层layout进行矫正都生成还是怎么样（不太懂这个版图文件的层数是怎么定义的），目前是采用GUI来操作的，如果是对全部数据集进行OPC操作的话如何通过脚本化操作实现。</p>
</li>
<li><p>问题3： SARF插入不会目前不会操作， 以及对于最后的图像导出是怎么样的？ 是一层一层版图的导出还是怎么样， 颜色怎么定义， 。</p>
</li>
<li><p>问题4：不太理解这个版图里面的这些内容是什么， 顺便不太理解每一层layout是什么， 具体总结就是怎么生成数据集：</p>
</li>
</ul>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607204554631.png" alt="image-20230607204554631"></p>
<p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230607204707453.png" alt="image-20230607204707453"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/%E7%89%88%E5%9B%BE%E8%AE%BE%E8%AE%A1%E4%BB%8B%E7%BB%8D%EF%BC%8C-%E5%AE%B9%E5%99%AA%E5%A3%B0/" style="color: #00bcd4">版图设计介绍， 容噪声</a>
        </span>
        
    </div>
    <a href="/2023/06/06/%E7%89%88%E5%9B%BE%E8%AE%BE%E8%AE%A1%E4%BB%8B%E7%BB%8D/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/06/01/DeepLearningSystem/">
        <h2 class="post-title">DeepLearningSystem</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/6/1
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><p>深度学习系统，主要是实现一个类似pytorch的深度学习框架，包括计算图传播和GPU加速.</p>
<ul>
<li>github链接:<a target="_blank" rel="noopener" href="https://github.com/linkedlist771/DeepLearningSystem">linkedlist771&#x2F;DeepLearningSystem: 深度学习系统，主要是实现一个类似pytorch的深度学习框架，包括计算图传播和GPU加速 (github.com)</a></li>
</ul>
<h3 id="踩过的坑"><a href="#踩过的坑" class="headerlink" title="踩过的坑"></a>踩过的坑</h3><ul>
<li><code>Linear</code> 层神经网络前向传播， 代码如下：</li>
</ul>
<pre><code class="Python">class Linear(Module):
    def __init__(self, in_features, out_features, bias=True, device=None, dtype=&quot;float32&quot;):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        ### BEGIN YOUR SOLUTION
        #self.bias = bias
        self.device = device
        self.dtype = dtype
        # 如果有偏置的话
        weight = init.kaiming_uniform(in_features, out_features, nonlinearity=&quot;relu&quot;, device=device, dtype=dtype)
        self.weight = Tensor(weight)
        if bias:
            # 然而，如果你的代码中某些地方假定偏置是一个二维张量，而且第一个维度为1，那么reshape就是必须的。
            # 这可能是为了保持与特定操作的兼容性，例如广播或矩阵乘法。
            # 另外一种可能的原因是，在使用Kaiming初始化时，fan_in和fan_out参数的顺序可能会影响到初始化的结果。
            # 在你的代码中，可能作者想要使用out_features作为fan_in来进行初始化。然后，通过reshape操作将偏置调整为正确的形状。
            # 不过在偏置初始化中，一般不需要这样做，因为偏置通常都被初始化为零或者接近零的小值。
            self.bias = init.kaiming_uniform(out_features, 1, dtype=dtype).reshape((1, out_features))
            # self.bias = init.kaiming_uniform(1, out_features, nonlinearity=&quot;relu&quot;, device=device, dtype=dtype)
        else:
            self.bias = None
        # raise NotImplementedError()
        ### END YOUR SOLUTION

    def forward(self, X: Tensor) -&gt; Tensor:
        ### BEGIN YOUR SOLUTION
        if self.bias:
            # 如果有偏置的话
            a_l = ops.matmul(X, self.weight)
            return a_l + self.bias
        else:
            return ops.matmul(X, self.weight)
        # raise NotImplementedError()
        ## END YOUR SOLUTION
</code></pre>
<p>踩坑点：如果含有偏置bias的情况下，由于<code>out_features</code>可能不是一维的，默认生成(1,out_features) 形状的张量， 在多维情况将出现错误，所以需要<code>init.kaiming_uniform(out_features, 1, dtype=dtype).reshape((1, out_features))</code>先生成这种形状的Tensor然后进行reshape保持兼容性。</p>
<h2 id="一个两层的神经网络"><a href="#一个两层的神经网络" class="headerlink" title="一个两层的神经网络"></a>一个两层的神经网络</h2><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230617174413453.png" alt="image-20230617174413453"></p>
<h2 id="梯度下降求导"><a href="#梯度下降求导" class="headerlink" title="梯度下降求导"></a>梯度下降求导</h2><p><img src="/../../../../../AppData/Roaming/Typora/typora-user-images/image-20230617174451412.png" alt="image-20230617174451412"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%EF%BC%8C-DeepLearning-system/" style="color: #00bcd4">深度学习系统， DeepLearning system</a>
        </span>
        
    </div>
    <a href="/2023/06/01/DeepLearningSystem/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/06/01/GN%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%8B%E8%BD%BD%E9%93%BE%E6%8E%A5/">
        <h2 class="post-title">GN机器人下载链接</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/6/1
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p>之前制作的ChatGPT移动版本（windows+安卓的api已耗尽，请下载新版本， PS， 熟悉软件热更新的小伙伴可以联系我帮忙优化捏), <code>下载链接</code>更新为：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://101.132.169.133:5000/file/download/chatgpt%E7%A7%BB%E5%8A%A8%E7%89%88%28GN%E5%88%B6%E4%BD%9C%29V0.6.apk">安卓版本</a></li>
<li><a target="_blank" rel="noopener" href="http://101.132.169.133:5000/file/download/Win%E7%B3%BB%E7%BB%9Fchatgpt%E7%A7%BB%E5%8A%A8%E7%89%88(GN%E5%88%B6%E4%BD%9C)V0.6.zip">Windows版本</a></li>
</ul>
<p>如果还有问题，请联系<code>QQ:2317431442</code></p>
<p>如果觉得不错给我买杯可乐捏：</p>
<p><img src="/../images/wechat.png" alt="wechat"></p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
    </div>
    <a href="/2023/06/01/GN%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%8B%E8%BD%BD%E9%93%BE%E6%8E%A5/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/05/30/%E5%88%A9%E7%94%A8ChatGLM%E5%88%A9%E7%94%A8QQ%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E5%AD%97%E5%AD%AA%E7%94%9F/">
        <h2 class="post-title">利用ChatGLM利用QQ数据集构建自己的数字孪生</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/5/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h3 id="项目简介："><a href="#项目简介：" class="headerlink" title="项目简介："></a>项目简介：</h3><p>本项目源自<a target="_blank" rel="noopener" href="https://github.com/kcxain/CloneLLM">kcxain</a>, 本人只是将其在本地部署完成， 作者使用了<code>NVIDIA A100 80GB</code> 并不是每个人都拥有的。也不是每一个人都拥有<code>Linux</code>系统进行部署，并且对于<code>ChatGLM</code>的部署，作者没有说的很明白。所以这个项目将分为两个部分：</p>
<ol>
<li><code>ChatGLM</code>的部署</li>
<li>基于该项目的自我数据集的训练</li>
</ol>
<h3 id="ChatGLM部署"><a href="#ChatGLM部署" class="headerlink" title="ChatGLM部署"></a>ChatGLM部署</h3><ul>
<li>ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
<li>结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
<li>ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
<li>经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
<li>为了方便下游开发者针对自己的应用场景定制模型，他们同时实现了基于 P-Tuning v2 的高效参数微调方法 (使用指南) ，INT4 量化级别下最低只需 7GB 显存即可启动微调<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
<li>ChatGLM-6B 开源模型旨在与开源社区一起推动大模型技术发展，恳请开发者和大家遵守开源协议，勿将开源模型和代码及基于开源项目产生的衍生物用于任何可能给国家和社会带来危害的用途以及用于任何未经过安全评估和备案的服务<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
</ul>
<p>清华的 ChatGLM 项目在 2023 年也发布了一些重要的更新：</p>
<ul>
<li>2023 年 5 月 17 日，他们发布了 VisualGLM-6B，一个支持图像理解的多模态对话语言模型<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
<li>2023 年 5 月 15 日，他们更新了 v1.1 版本 checkpoint，训练数据增加英文指令微调数据以平衡中英文数据比例，解决英文回答中夹杂中文词语的现象<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">1</a>。</li>
</ul>
<h4 id="部署ChatGLM"><a href="#部署ChatGLM" class="headerlink" title="部署ChatGLM"></a>部署ChatGLM</h4><ol>
<li><p>进入<a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">ChatGLM</a> 主页，找到git链接，git到本地即可:</p>
<p><img src="/../images/image-20230530173507682.png" alt="image-20230530173507682"></p>
<p>然后使用git 命令下载到本地即可：</p>
<pre><code class="bash">git clone git@github.com:THUDM/ChatGLM-6B.git
</code></pre>
<p>如果不熟悉git， 也可以点击主页的下载按钮下载zip文件进行解压。</p>
<p><img src="/../images/image-20230530173631415.png" alt="image-20230530173631415"></p>
</li>
<li><p>下载完ChatGLM主页程序后，现在需要下载模型的权重文件。进入ChatGLM的<a target="_blank" rel="noopener" href="https://huggingface.co/THUDM/chatglm-6b">hugging face hub</a></p>
<p>利用按照主页教程利用git lsf 进行下载即可。 </p>
<p>如果这一步也存在问题，也可以先下载项目文件， 将权重文件下载并保存这个文件里面的其他的文件到chatglm-6b文件夹（<code>注意，该文件夹要在之前的ChatGLM文件夹下</code>）：</p>
<p><img src="/../images/image-20230530174240127.png" alt="image-20230530174240127"></p>
</li>
<li><p>下载完毕后，我们便可以试着运行一下预训练的<code>ChatGLM</code>了， 注意，这里根据你电脑的显存不同采用的量化规则也不太相同， 官网的建议如下：</p>
</li>
</ol>
<table>
<thead>
<tr>
<th><strong>量化等级</strong></th>
<th><strong>最低 GPU 显存</strong>（推理）</th>
<th><strong>最低 GPU 显存</strong>（高效参数微调）</th>
</tr>
</thead>
<tbody><tr>
<td>FP16（无量化）</td>
<td>13 GB</td>
<td>14 GB</td>
</tr>
<tr>
<td>INT8</td>
<td>8 GB</td>
<td>9 GB</td>
</tr>
<tr>
<td>INT4</td>
<td>6 GB</td>
<td>7 GB</td>
</tr>
</tbody></table>
<p>​       如果你的电脑是8G显存， 本人实测也只能选择<code>INT4</code> 量化， 对于6G以下显存的用户不太友好，你这里可以尝试<a target="_blank" rel="noopener" href="https://github.com/Jittor/JittorLLMs">清华的另一个项目</a> , 基于<code>动态计算图</code>的<code>硬盘，内存，显存</code>动态交换量化的方式进行运行。笔者的显卡为<code>NVIDIA RTX 3070Ti-Laptop</code>， 显存为8G，选择为<code>INT4</code>量化。</p>
<p>​       现在我们已经完成了所有的预设步骤啦，现在可以部署实验了， 选择这个文件：</p>
<p><img src="/../images/image-20230530175109292.png" alt="image-20230530175109292"></p>
<p>将第7-8行的代码修改为：</p>
<p><code>INT4量化</code>：</p>
<pre><code class="python">tokenizer = AutoTokenizer.from_pretrained(&quot;chatglm-6b&quot;, trust_remote_code=True)
model = AutoModel.from_pretrained(&quot;chatglm-6b&quot;, trust_remote_code=True).quantize(4).half().cuda()
</code></pre>
<p>或者<code>INT8量化</code>:</p>
<pre><code class="python">tokenizer = AutoTokenizer.from_pretrained(&quot;chatglm-6b&quot;, trust_remote_code=True)
model = AutoModel.from_pretrained(&quot;chatglm-6b&quot;, trust_remote_code=True).quantize(8).half().cuda()
</code></pre>
<p>然后进行运行即可，现在我们就可以给他提问了，取决于你的显卡的显存和算力，回复速度可能存在差距。</p>
<p><img src="/../images/image-20230530183000569.png" alt="image-20230530183000569"></p>
<p><img src="/../images/image-20230530183459075.png" alt="image-20230530183459075"></p>
<h4 id="基于自己的QQ数据集的P-tuning"><a href="#基于自己的QQ数据集的P-tuning" class="headerlink" title="基于自己的QQ数据集的P-tuning"></a>基于自己的QQ数据集的P-tuning</h4><p>参考<a target="_blank" rel="noopener" href="https://github.com/kcxain/CloneLLM">kcxain</a>,的介绍，你现在应该能够完成数据集的构建，然后我们就可以开始训练了， 这里需要注意的是，作者使用的是<code>Linux</code>系统编写的训练脚本，所以我们需要在<code>windows</code>下进行训练需要进行修改。</p>
<p>这里我们选择<code>P-tuning</code>下面的<code>main.py</code>文件</p>
<p><img src="/../images/image-20230530175722861.png" alt="image-20230530175722861"></p>
<p>在pycharm中我们可以在这里设置参数</p>
<p><img src="/../images/image-20230530175742124.png" alt="image-20230530175742124"></p>
<p>在这里输入参数：</p>
<p><img src="/../images/image-20230530175804152.png" alt="image-20230530175804152"></p>
<p>我这里选择的参数为：</p>
<pre><code class="bash">--quantization_bit
4
--do_train
--train_file
我的好友.txt.json
--prompt_column
prompt
--response_column
response
--history_column
history
--overwrite_cache
--model_name_or_path
..\chatglm-6b
--output_dir
chatglm_qq
--overwrite_output_dir
--max_source_length
128
--max_target_length
128
--per_device_train_batch_size
4
--per_device_eval_batch_size
1
--gradient_accumulation_steps
2
--predict_with_generate
--max_steps
10000
--logging_steps
10
--save_steps
1000
--learning_rate
0.002
--pre_seq_len
128
</code></pre>
<p>这里需要说明一下，根据你的显卡的显存大小，可以适当调整<code>batch_size</code>,<code>max_source_length</code>,<code>max_target_length  </code>从而减小你的显存消耗，这里我设置的参数的显存占用为<code>7.8/8G</code>, 基本上吃满了。</p>
<p><img src="/../images/image-20230530180019282.png" alt="image-20230530180019282"></p>
<p>然后我们运行后便可以看到训练的log输出了。</p>
<p><img src="/../images/image-20230530180052355.png" alt="image-20230530180052355"></p>
<p>这里我设置的每隔1000个epoch进行一个保存，在训练1000个epoch后，我终止了。这是目前的对话效果：</p>
<p>按照博主的介绍，这里我们注意一下，传入的参数是在py程序中</p>
<pre><code class="BASH">--model_name_or_path
..\chatglm-6b
--pre_seq_len
128
--ptuning_checkpoint
chatglm_qq/checkpoint-1000
</code></pre>
<p><img src="/../images/image-20230530185103745.png" alt="image-20230530185103745"></p>
<p>好吧，看来我和QQ群友主要的讨论内容还是关于文件接受&#x2F;传输的， 太尴尬了，后面准备拿QQ群聊数据训练一下 ，毕竟我的活跃主要是在QQ群聊立马🤣。 </p>
<p>笔者又进行了训练，得到如下效果：</p>
<p><img src="/../images/image-20230530201939083.png" alt="image-20230530201939083"></p>
<p>怎么说呢，差强人意吧， 可能还是预料数据集质量较差。</p>
<h3 id="构建自己的数字孪生"><a href="#构建自己的数字孪生" class="headerlink" title="构建自己的数字孪生"></a>构建自己的数字孪生</h3><p>在前文中，我们完成了基于自己的QQ数据集的<code>P-tuning</code>得到的自己的对话模型，现在我们可以部署了，这里我采用的是一个常用的解决方案<code>cqhttp+nonebot</code>, 然后选择基于已有插件进行修改得到。<code>nonebot</code>是一个基于异步架构搭建的， 基于此，我们基于<code>fast api</code>搭建一个异步路由构建自己的数字孪生。借助<code>GPT4</code>，简单描述需求后便可以得到所需要的代码：</p>
<pre><code class="python">from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import (
    AutoConfig,
    AutoModel,
    AutoTokenizer,
)
from arguments import ModelArguments, DataTrainingArguments
import torch
import os

app = FastAPI()

model = None
tokenizer = None


class Prompt(BaseModel):
    text: str

@app.on_event(&quot;startup&quot;)
async def load_model():
    global model, tokenizer

    model_args = ModelArguments(
        model_name_or_path=&quot;..\\chatglm-6b&quot;,
        ptuning_checkpoint=&quot;chatglm_qq/checkpoint-600&quot;,
        pre_seq_len=128,
        prefix_projection=False,
        quantization_bit=8,
    )

    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path,
                                              trust_remote_code=True)
    config = AutoConfig.from_pretrained(model_args.model_name_or_path,
                                        trust_remote_code=True)

    config.pre_seq_len = model_args.pre_seq_len
    config.prefix_projection = model_args.prefix_projection

    if model_args.ptuning_checkpoint is not None:
        print(
            f&quot;Loading prefix_encoder weight from &#123;model_args.ptuning_checkpoint&#125;&quot;
        )
        model = AutoModel.from_pretrained(model_args.model_name_or_path,
                                          config=config,
                                          trust_remote_code=True).quantize(4).half().cuda()
        prefix_state_dict = torch.load(
            os.path.join(model_args.ptuning_checkpoint, &quot;pytorch_model.bin&quot;))
        new_prefix_state_dict = &#123;&#125;
        for k, v in prefix_state_dict.items():
            if k.startswith(&quot;transformer.prefix_encoder.&quot;):
                new_prefix_state_dict[
                    k[len(&quot;transformer.prefix_encoder.&quot;):]] = v
        model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)
    else:
        model = AutoModel.from_pretrained(model_args.model_name_or_path,
                                          config=config,
                                          trust_remote_code=True)

    if model_args.quantization_bit is not None:
        print(f&quot;Quantized to &#123;model_args.quantization_bit&#125; bit&quot;)
        model = model.quantize(model_args.quantization_bit)

    if model_args.pre_seq_len is not None:
        # P-tuning v2
        model = model.half().cuda()
        model.transformer.prefix_encoder.float().cuda()

    model = model.eval()
    print(f&quot;模型加载成功&quot;)


@app.post(&quot;/chatglm/qq/ask&quot;)
async def ask(prompt: Prompt):
    global model, tokenizer
    if model is None or tokenizer is None:
        raise HTTPException(status_code=503, detail=&quot;Model not loaded&quot;)

    # 现在你需要使用model和tokenizer处理prompt并生成response
    # response = model.chat(prompt)
    # 调用模型的 chat 方法
    history = []
    response, history = model.chat(
        tokenizer,
        prompt.text,
        history=history,
    )

    return &#123;&quot;response&quot;: response&#125;



async def main():
    await load_model()
    while True:
        prompt = input(&quot;请输入：&quot;)
        response = await ask(Prompt(text=prompt))
        print(response)


if __name__ == &quot;__main__&quot;:
    import asyncio
    asyncio.run(main())
</code></pre>
<p>启动代码为：</p>
<pre><code class="bash"> uvicorn qq_chat_app:app --host 0.0.0.0 --port 1414 --reload
</code></pre>
<p>简单编写测试代码测试端口：</p>
<pre><code class="python">import requests
def get_chatglm(prompt):
    url = &#39;http://localhost:1414/chatglm/qq/ask&#39;
    data = &#123;
        &#39;text&#39;: prompt
    &#125;
    response = requests.post(url, json=data)

    print(response.json()[&quot;response&quot;])

get_chatglm(&quot;你是谁？ 你能干什么？ 今天晚上什么吃什么？&quot;)
</code></pre>
<p>得到结果:</p>
<pre><code class="bash">我是一个名为 ChatGPT 的人工智能助手，我可以通过自然语言处理技术，回答您的问题和提供信息。
</code></pre>
<p>成功测试通接口，暂时基于<code>nonebot2</code>搭建了一个简单的回复框架，效果如下：</p>
<p><img src="/../images/image-20230530214355521.png" alt="image-20230530214355521"></p>
<p><img src="/../images/image-20230530214405417.png" alt="image-20230530214405417"></p>
<p><img src="/../images/image-20230530214524635.png" alt="image-20230530214524635"></p>
<p>由于目前<code>tx</code>对QQ机器人风控严重，回复了几次就不行了，而且回复效果只能算一般吧。</p>
<h1 id="Todo-List"><a href="#Todo-List" class="headerlink" title="Todo List"></a>Todo List</h1><ul>
<li><input disabled type="checkbox"> 优化数据集构建， 提高对话质量，增强模型训练。</li>
<li><input disabled type="checkbox"> 尝试注入<code>RWKV</code>, <code>LLM</code>等模型进行构建。</li>
<li><input disabled type="checkbox"> 暂时还没想好。</li>
</ul>

            
        </div>
    </div>
    <div class="post-tags">
        
        <span class="icon">
            <i class="fa-solid fa-tags fa-fw"></i>
        </span>
        
        
        <span class="tag">
            
            <a href="/tags/ChatGLM%EF%BC%8C-%E6%95%B0%E5%AD%97%E5%AD%AA%E7%94%9F%EF%BC%8C-QQ%E6%95%B0%E6%8D%AE%E9%9B%86/" style="color: #ffa2c4">ChatGLM， 数字孪生， QQ数据集</a>
        </span>
        
    </div>
    <a href="/2023/05/30/%E5%88%A9%E7%94%A8ChatGLM%E5%88%A9%E7%94%A8QQ%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E5%AD%97%E5%AD%AA%E7%94%9F/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/05/30/paper-reading-DAMO/">
        <h2 class="post-title">DAMO(Deep Agile Mask Optimization for Full-Chip Scale, 用于全芯片规模的深度学习敏捷掩膜优化）</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/5/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li><strong>作者</strong>：Haoyu Yang、Zongyi Li、Kumara Sastry、Saumyadip Mukhopadhyay、Mark Kilgard、Anima Anandkumar、Brucek Khailany、Vivek Singh、Haoxing Ren</li>
<li><strong>发布时间</strong>：（发表日期）</li>
<li><strong>来源</strong>：（期刊、会议等）</li>
<li><strong>关键词</strong>：光刻建模，神经网络，双波段，光学启发</li>
</ul>
<h2 id="目的与动机"><a href="#目的与动机" class="headerlink" title="目的与动机"></a>目的与动机</h2><ul>
<li>光学近接校正（OPC）在传统设计流程中被广泛应用于可制造性优化。</li>
<li>传统方法使用光刻模型进行 OPC，但可能会遇到过高的计算开销。</li>
<li>大部分方法关注优化单个局部剪辑，而没有解决如何处理全芯片级别的问题。</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ul>
<li>本文提出了一种名为 DAMO 的高性能、可扩展的深度学习支持的全芯片级 OPC 系统。</li>
<li>DAMO 是一种端到端的掩模优化范式，包括一个深度光刻模拟器（DLS）用于光刻建模，以及一个深度掩模生成器（DMG）用于掩模图案生成。</li>
<li>提出了一种专门为 DAMO 设计的新型布局分割算法，由 DBSCAN 聚类和 KMeans++ 聚类组成，用于处理全芯片 OPC 问题。</li>
</ul>
<h4 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h4><ul>
<li><p>optical proximity correction (OPC， 光学接近矫正)超大规模集成电路(VLSI)系统的不断缩小带来了不可避免的光刻邻近效应，导致制造良率下降。 </p>
<p>主流的OPC的技术包括：</p>
<ul>
<li></li>
</ul>
</li>
</ul>
<h3 id="目前光刻OPC的缺点"><a href="#目前光刻OPC的缺点" class="headerlink" title="目前光刻OPC的缺点"></a>目前光刻OPC的缺点</h3><ol>
<li><p>耗时：模型驱动&#x2F;ILT方法需要大量光刻模拟和掩模优化调用。</p>
</li>
<li><p>低分辨率：基于机器学习的 OPC 工作局限于低分辨率图像。</p>
</li>
<li><p>无法容忍分辨率损失：传统 OPC 引擎仍需处理低分辨率限制。</p>
</li>
<li><p>单剪辑 OPC 不实用：基于机器学习的方法局限性较大。</p>
</li>
<li><p>针对全片尺度问题：少有讨论如何从全片尺度解决 OPC 问题。</p>
</li>
<li><p>运行时开销大：传统方法在全片 OPC 任务中面临运行时开销难题。</p>
</li>
<li><p>资源消耗：D2S 等方法在硬件和软件上消耗大量资源。</p>
</li>
<li><p>数据集限制：基于学习的方法在全片掩模优化方面受限于数据集和低晶圆图案保真度。</p>
<h1 id="本文完成的内容"><a href="#本文完成的内容" class="headerlink" title="本文完成的内容"></a>本文完成的内容</h1><ol>
<li>设计了 DCGAN-HD，通过重新设计 DCGAN 的生成器和判别器，实现了具有竞争力的高分辨率特征提取器（1024 × 1024）。</li>
<li>基于 DCGAN-HD 构建了 DLS 和 DMG。DLS 能进行高分辨率光刻模拟，通过与 DLS 的逆校正一起训练，DMG 可直接生成高质量掩模。</li>
<li>开发了一种高效的无缝全片分割算法，由 DBSCAN 和 KMeans++ 聚类算法组成，使 DAMO 可以应用于任意大小的布局。</li>
<li>提出使用基于图的计算技术和并行技术分别加速 DBSCAN 和 KMeans++ 在 GPU 上的计算。此外，还使用 TensorRT 部署了所提出的 DCGAN-HD，从而实现更快的推理。</li>
<li>将提出的框架与最先进的商业工具 Calibre 进行了比较：在单剪辑 OPC 任务中加速 5 倍，全片 OPC 任务中加速 1.3 倍，同时保持更好的解决方案质量。</li>
</ol>
<h3 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h3><ul>
<li><strong>cGAN基础</strong></li>
</ul>
<p>cGAN（Conditional Generative Adversarial Networks，条件生成对抗网络）[18]，[19] 是一种类似于经典 GAN（Generative Adversarial Networks，生成对抗网络）[20] 的模型，由一个生成器和一个判别器组成。生成器被训练以生成遵循某种分布的样本，使得判别器无法识别这些数据是来自生成器还是来自训练数据集。cGAN 与 GAN 的不同之处在于某些限制，例如生成器的输入和输出可以具有更强的关联性。</p>
<p>在超大规模集成电路中，典型的 cGAN 应用包括 GANOPC[9] 和 LithoGAN[14]。前者被设计用于布局掩模合成，后者则侧重于单通孔&#x2F;接触形状的光刻轮廓预测。cGAN 的优点在于生成器和判别器之间的竞争性训练过程，可以促使生成器生成更真实、高质量的样本。而在光刻掩模生成和预测等任务中，cGAN 能够利用输入布局的条件信息，生成更为精确且符合实际需求的掩模。</p>
<h4 id="DAMO框架引入了以下术语和评估指标："><a href="#DAMO框架引入了以下术语和评估指标：" class="headerlink" title="DAMO框架引入了以下术语和评估指标："></a>DAMO框架引入了以下术语和评估指标：</h4><ul>
<li><p>**定义1 (mIoU)**：给定两个形状P和G，P和G之间的IoU为 $IoU(P, G) &#x3D; \frac{P \cap G}{P \cup G}$。mIoU 是平均IoU。</p>
</li>
<li><p>**定义2 (像素准确度)**：像素准确度（pixAcc）定义为图像上正确分类像素的百分比。</p>
</li>
<li><p>**定义3 (平方 L2 误差)**：设w和y分别为设计图像和晶圆图像，平方L2误差由 $||w - y||_2^2$ 计算。</p>
</li>
<li><p>**定义4 (PV Band)**：给定一组工艺条件下的光刻仿真轮廓，PV Bands 是这些条件下所有轮廓的区域。</p>
</li>
<li><p><strong>问题1（掩模优化）</strong>：给定设计图像w，掩模优化的目标是生成相应的掩模x，使得光刻过程后剩余的图案y尽可能接近w，换句话说，最小化光刻图像的PV Band和平方L2误差。</p>
</li>
</ul>
<p>掩模质量通过与目标图像的晶圆图像保真度评估，主要采用三种缺陷检测器：EPE（边缘放大误差）、桥和颈部。EPE计算目标边缘到光刻轮廓的距离，颈部缺陷关注关键尺寸误差，桥接检测器寻找意外的电线缩短。为确保光刻后图案尽量接近目标图案，采用平方L2误差和PV Band评估掩模质量，分别衡量标称工艺条件下的质量和生成掩模的稳健性。</p>
<p>PV Band（过程变差带）是在一组工艺条件下，衡量掩膜对光刻过程中各种变化的稳健性的指标。在光刻过程中，不同的工艺条件可能会导致不同的光刻轮廓，因此在这些条件下的光刻仿真轮廓之间存在一定的区域差异。PV Band就是描述这些条件下所有轮廓区域差异的指标。一个较小的PV Band表示生成的掩模在工艺条件变化下更具稳健性，光刻过程后产生的图案与目标图案更为接近。</p>
</li>
</ol>
<h2 id="DAMO框架"><a href="#DAMO框架" class="headerlink" title="DAMO框架"></a>DAMO框架</h2><p><img src="/../images/image-20230504202444044.png" alt="image-20230504202444044"></p>
<h4 id="DMG"><a href="#DMG" class="headerlink" title="DMG"></a>DMG</h4><p>DMG是DAMO的第二部分，它与DLS共享相同的体系结构。正向光刻过程可以用下式描述<br>$$<br>\boldsymbol{Z}&#x3D;f(\boldsymbol{M})<br>$$<br>传统的ILT试图根据给定的光刻模型获得最优掩模$\boldsymbol{M_{opt}}$，该模型表示为<br>$$<br>\boldsymbol{M}_{\mathrm{opt}}&#x3D;f^{-1}\left(\boldsymbol{Z}_t\right)<br>$$</p>
<h4 id="通过更高的分辨率提高精—–DCGAN-HD-高分辨率解决方案"><a href="#通过更高的分辨率提高精—–DCGAN-HD-高分辨率解决方案" class="headerlink" title="通过更高的分辨率提高精—–DCGAN-HD:高分辨率解决方案"></a>通过更高的分辨率提高精—–DCGAN-HD:高分辨率解决方案</h4><ul>
<li>DCGAN-HD用于模拟光刻。</li>
</ul>
<h4 id="数据集准备"><a href="#数据集准备" class="headerlink" title="数据集准备"></a>数据集准备</h4><p><img src="/../images/image-20230504230501724.png" alt="image-20230504230501724"></p>
<ul>
<li><p>从零开始建立训练集</p>
<p>生成训练图像需要五个步骤，包括设计生成、SRAF插入(带设计规则检查)、OPC、光刻仿真、布局到图像转换。</p>
<ul>
<li>**设计一个设计模式: **</li>
</ul>
<p>所有通孔图案(70 × 70 nm2)都被限制在1024 × 1024 nm2的窗口中。其次，通过改变通孔密度，我们可以控制单个窗口中通孔图案的数量。为了减少训练集随机分布带来的偏差，通过对经过数进行均匀分组。</p>
<ul>
<li><strong>SRAF插入和DRC</strong></li>
</ul>
<p>使用Mentor Calibre[17]进行SRAF插入和设计规则检查。请注意，过孔图案可能出现在设计区域内的任何位置，Calibre在执行SRAF插入时将在过孔图案的中心创建一个新的设计层。这使得模型更容易学习，因为所有的via模式都位于图像的中心附近。此外，它还为我们进一步开发加速算法提供了指导。由于设计面积为1024 × 1024 nm2，当有2个以上的via图案时，可能会有一些SRAF图案出现在设计区域之外。一个更大的窗口2048×2048 nm2将用于捕获所有SRAF模式，它们与设计窗口共享同一个中心。</p>
<ul>
<li><strong>OPC，光刻仿真和图像生成</strong></li>
</ul>
<p>我们使用由Calibre生成的掩模和晶圆图案作为ground truth。</p>
<ul>
<li><strong>DLS的训练</strong></li>
</ul>
<p><img src="/../images/image-20230505105107484.png" alt="image-20230505105107484"></p>
<ul>
<li><strong>训练DMG</strong></li>
</ul>
<p><img src="/../images/image-20230505105728177.png" alt="image-20230505105728177"></p>
</li>
<li><p>所提出的DAMO使用Python和PyTorch库[35]实现。在DLS和DMG的训练阶段，我们采用了Adam优化器[36]，基础学习率和动量参数分别设置为0.0002和（0.5，0.999）。在所有模型中，LeakyReLU中的泄漏斜率设置为0.2。我们将批次大小设置为4，最大训练轮次设置为100。权重参数λ0、λ1、α0、α1和λ2分别设置为100、100、30、30和20。可以通过PyTorch的评估模式实现DLS的固定参数。训练后，生成的掩模层将转换为GDSII布局文件，然后输入到Mentor Calibre进行光刻模拟验证。我们使用四个Nvidia TITAN Xp GPU进行训练，一个用于测试。我们采用的评估指标有mIoU、pixAcc、L2误差和PV Band。这里，PV Band是由Calibre计算的。</p>
</li>
</ul>
<p>其中Calibre的使用手册：</p>
<p><a href="calibreManual.pdf">[17]Calibre V erification User’s Manual, Mentor Graph., Wilsonville, OR, USA, 2008. </a></p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><ul>
<li><p><a target="_blank" rel="noopener" href="http://www.ispd.cc/contests/19/#benchmarks">ISPD-2019</a>：此设计来自ISPD 2019初始详细布线竞赛[25]。布局是使用商业布点和布线工具进行合成的。通过将过孔层输入到OPC和仿真流程中，获得名义电阻轮廓。训练集包括$10 \mathrm{<del>K} 4 \mu \mathrm{m}^2$的平铺，这些平铺是使用遵循与[25]中设计相同设计规则的开源布局生成器生成的。在测试中，[25]中的过孔层也被切成 $4 \mu \mathrm{m}^2$ 的平铺，总计 $11 \mathrm{</del>K}$ 实例，转换为 $2000 \times 2000$（ISPD-2019 (H)）和 $1000 \times 1000$（ISPD-2019 (L)）图像。在大平铺模拟实验中，我们从[25]中选择十个最密集的 $64 \mu \mathrm{m}^2$ 平铺，并将它们转换为 $8000 \times 8000$ 图像。</p>
<ol>
<li><strong><font color="red">摘要</font></strong></li>
</ol>
<p>2019年ISPD竞赛在2018年ISPD详细布线竞赛的基础上，增加了更符合实际工业应用的设计规则设定。</p>
<p>详细布线过程可以分为两个步骤。首先，进行初始详细布线，以生成详细布线解决方案并处理主要设计规则。然后进行详细布线优化，修复剩余的设计规则违规问题。本次竞赛主要关注初始详细布线步骤。</p>
<p>假设全局布线结果已经针对某些指标（如时序）进行了良好的优化，详细布线器需要尽可能遵循全局布线结果。这样，优化的指标得以保留，同时避免了设计规则违例。例如，图1(a)显示了一个具有源引脚A和汇引脚B、C、D的网络的全局布线结果。由于从A到B的路径对时序至关重要，全局布线器识别出一条从A到B的短路径。然而，该路径穿过了局部布线拥堵区域，这一区域并未被全局布线器发现。如果详细布线器如图1(b)所示，在该区域上布线，将会产生设计规则违例。图1(c)显示了一个没有短路&#x2F;间距违例的布线结果，但它会导致从A到B的路径时序退化。另一方面，图1(d)显示了一个理想的解决方案。</p>
</li>
</ul>
<p><img src="http://www.ispd.cc/contests/19/fig1.png" alt="img"></p>
<p>​	      为了尽量减小对网络拓扑的干扰，初始详细布线起着重要作用。如果初始详细布线结果能够满足大部分常见的布线规则，即使没有    完全达到DRC要求，后续的详细布线优化就不太可能对布线结果造成很大干扰。</p>
<p><font color="red"><a target="_blank" rel="noopener" href="http://www.ispd.cc/contests/19/tutorial.htm">相关教程</a></font></p>
<p>在本教程中，我们将使用一个仅包含11个网络的样本基准来介绍基准格式、竞赛问题的目标&#x2F;约束以及如何使用Cadence P&amp;R工具Innovus评估您的布线方案。请从以下链接下载样本基准到您的Linux服务器，然后使用命令“tar zxvf ispd19_sample.tgz”解压缩下载的文件。</p>
<p><em>注意：</em>ispd19_sample.tgz、ispd19_sample2.tgz 和 ispd19_sample3.tgz 是在 ISPD 2018竞赛中使用的相同样本基准。而ispd19_sample4.tgz 是一个新的样本基准，其中包含了本次竞赛所需的新规则。</p>
<p>“.input.lef”文件包含了竞赛中需要考虑的布线规则和设计信息。 “.input.def”文件包含了设计的布局信息、引脚和阻塞。 “.input.guide”文件包含了详细布线器应遵循的全局布线解决方案。每个基准测试都将有这三个文件来表示详细布线问题的实例。请参考以下文档，了解本次竞赛中规则和目标的详细信息。</p>
<p>另一方面，“.solution.good.def”和“.solution.bad.def”分别代表了一个好的布线解决方案和一个不好的布线解决方案。这两个“解决方案”文件的大部分内容与“*.input.def”文件相同，但解决方案文件包含每个网络的布线信息。在后面的部分，我们将使用这两个文件来介绍如何使用Innovus评估详细布线器生成的布线解决方案。其他基准测试中将不提供这两个文件，它们仅用于教程目的。您的可执行文件生成的解决方案文件格式应遵循上述链接中介绍的LEF&#x2F;DEF格式。</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
    </div>
    <a href="/2023/05/30/paper-reading-DAMO/" class="go-post">阅读全文</a>
</div>

<div class="post">
    <a href="/2023/05/30/Infinite-GPT4-Usage/">
        <h2 class="post-title">GPT4逆向IOS模型无限次数油猴脚本编写</h2>
    </a>
    <div class="category-and-date">
        
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2023/5/30
        </span>
        
        
    </div>
    <div class="description">
        <div class="content" v-pre>
            
            <p><a target="_blank" rel="noopener" href="https://github.com/linkedlist771/infiniteGPT4">GitHub项目链接</a></p>
<p><a target="_blank" rel="noopener" href="https://greasyfork.org/zh-CN/scripts/467074-%E6%97%A0%E9%99%90gpt4/">脚本链接</a></p>
<h2 id="1：起因"><a href="#1：起因" class="headerlink" title="1：起因"></a>1：起因</h2><p><img src="/../images/image-20230529191948609.png" alt="image-20230529191948609"></p>
<p> 目前<code>ChatGPT</code> 如火如荼， 但是<code>GPT3.5</code>的模型能力有限，很多人选择开通<code>GPT Plus</code>来使用<code>GPT4</code>功能。</p>
<p>目前，<code>GPT PLUS</code> 用户可以使用以下模型：</p>
<ul>
<li>GPT 3.5<ul>
<li>优点：速度快，适合一般的需求。</li>
<li>缺点：模型参数较少，回答不够智能。</li>
</ul>
</li>
</ul>
<p><img src="/../images/image-20230529192326117.png" alt="image-20230529192326117"></p>
<ul>
<li>GPT 4<ul>
<li>优点：模型参数多，回答更智能，上下文理解更强。</li>
<li>缺点：有次数限制， 25次&#x2F;3小时， <code>对英文理解能力强于中文</code>，如果中文回答较烂，可以尝试英文。</li>
</ul>
</li>
</ul>
<p><img src="/../images/image-20230529192507875.png" alt="image-20230529192507875"></p>
<ul>
<li>GPT 4 - Browsing<ul>
<li>优点：添加了联网功能， 同上</li>
<li>缺点：同上</li>
</ul>
</li>
</ul>
<p><img src="/../images/image-20230529193218778.png" alt="image-20230529193218778"></p>
<p>GPT 4 - Plugin</p>
<ul>
<li>优点：各种千奇百怪的插件，其中文献检索功能较为不错，同上</li>
<li>缺点：同上</li>
</ul>
<p><img src="/../images/image-20230529193310330.png" alt="image-20230529193310330"></p>
<p> <strong>5.18日</strong> <code>OpenAI</code>推出IOS的APP版本，其中对于plus用户可以无限次数的使用<code>GPT4</code>模型。在登录IOS的过程中发现<code>OpenAI</code>在其中内嵌了一个网页，推测可以通过逆向功能实现网页版无限使用。</p>
<h1 id="2：具体实现"><a href="#2：具体实现" class="headerlink" title="2：具体实现"></a>2：具体实现</h1><p><strong>在<code>IOS</code>设备使用无限次数的GPT4后会留下历史记录：</strong></p>
<p><img src="/../images/image-20230529193753235.png" alt="image-20230529193753235"></p>
<p>推测可能是调用了不同的模型， 决定采取浏览器抓包的方式来实现。</p>
<h3 id="具体实现步骤"><a href="#具体实现步骤" class="headerlink" title="具体实现步骤"></a>具体实现步骤</h3><ol>
<li><p>什么是浏览器抓包：</p>
<p><strong>浏览器抓包</strong> 是一种网络调试方法，主要用于观察并分析浏览器和服务器之间的网络交互过程。具体来说，就是在浏览器发送请求和接收响应的过程中，捕获并记录网络数据包的过程。</p>
<h2 id="抓包的用途"><a href="#抓包的用途" class="headerlink" title="抓包的用途"></a>抓包的用途</h2><ul>
<li><strong>调试网络问题</strong>：开发者可以使用抓包工具检查请求和响应的详细信息，如HTTP头，内容，以及错误代码，等等，从而查找问题的来源。</li>
<li><strong>网络性能优化</strong>：通过抓包，我们可以观察网页加载的具体过程，以及每个请求所需的时间，这对于网络优化和性能提升非常有帮助。</li>
<li><strong>网络安全</strong>：抓包工具也常被用于检测网络安全问题，如未加密的数据，或是恶意的网络活动。</li>
</ul>
<h2 id="如何进行浏览器抓包"><a href="#如何进行浏览器抓包" class="headerlink" title="如何进行浏览器抓包"></a>如何进行浏览器抓包</h2><ol>
<li><strong>使用浏览器的开发者工具</strong>：大部分现代浏览器都内置了开发者工具，可以直接进行网络抓包。例如，在 Chrome 浏览器中，只需打开“开发者工具”（F12或右键点击页面然后选择”检查”），然后选择”Network”标签，就可以看到网络请求的详细信息。</li>
<li><strong>使用抓包工具</strong>：除了浏览器自带的工具，还有一些专业的抓包工具，如 Wireshark，Fiddler，Charles 等，这些工具功能更强大，能捕获更多类型的网络数据包。</li>
</ol>
</li>
<li><p>如何进行浏览器抓包</p>
</li>
</ol>
<p>​		本人的使用的浏览器为<code>Edge</code>浏览器， <code>Chrome</code>浏览器同理， 在浏览器中按下<code>F12</code>键打开调试工具，选择网络这一项。</p>
<p><img src="/../images/image-20230529194415396.png" alt="image-20230529194415396"></p>
<p>​        然后清空历史的记录（点击上方的圆圈符号）， 然后当你在<code>ChatGPT</code>的网页版发送信息后， 在右侧的网络调试工具便可以看到你调用时发送的信息。比如说这里我们调用的是GPT4模型。</p>
<p><img src="/../images/image-20230529194947263.png" alt="image-20230529194947263"></p>
<p>​      当然，Mac同理，由于该<code>APP</code>只能在<code>IOS</code>设备上使用， 所以我借用了舍友的<code>MAC</code>进行了抓包，最后发现IOS设备无限使用的模型为<code>gpt-4-mobile</code>。 现在我们已经获取了我们所需要的所有内容了。现在就可以开始编写脚本来实现了。</p>
<ol start="3">
<li>脚本编写</li>
</ol>
<p>很多人觉得编写脚本代码是一键很难的事，但是有<code>GPT-4</code>的帮助后，其实不然，询问如何编写，他便可以很轻松的给出代码：</p>
<p><img src="/../images/image-20230529195510378.png" alt="image-20230529195510378"></p>
<p>稍加修改，便得到了第一版可以运行的代码：</p>
<pre><code class="javascript">// ==UserScript==
// @name        无限GPT4
// @namespace   https://github.com/linkedlist771
// @description 无限使用GPT4
// @license MIT
// @include     *
// @version     1
// @grant       none
// ==/UserScript==
 
(function() &#123;
    &#39;use strict&#39;;
 
    let realFetch = window.fetch;
    window.fetch = function(url, init) &#123;
        if (init &amp;&amp; init.method === &#39;POST&#39;) &#123;
            let data = JSON.parse(init.body);
            if (data.hasOwnProperty(&#39;model&#39;)) &#123;
                data.model = &#39;gpt-4-mobile&#39;;
                init.body = JSON.stringify(data);
            &#125;
        &#125;
        return realFetch(url, init);
    &#125;;
&#125;)()
</code></pre>
<p>现在这个代码已经可以正常运行了，在启动后，询问区别GPT4和3.5的问题，可以得到正确的答案，而且会看历史记录可以发现模型已经被修改了。确实为GPT4。</p>
<p><img src="/../images/image-20230529195952022.png" alt="image-20230529195952022"></p>
<p>在<a target="_blank" rel="noopener" href="https://greasyfork.org/zh-CN/users/1084702-lshang001">LShang001</a>和<a target="_blank" rel="noopener" href="https://greasyfork.org/zh-CN/users/116238-seto">Seto</a>的建议后， 对代码的部分部分逻辑进行了订正，<a target="_blank" rel="noopener" href="https://greasyfork.org/zh-CN/users/1047225-xuzihanshsjnsn">xuzihanshsjnsn</a> 帮忙完成了UI部分的设计。 基于此完成了<code>第四版</code>脚本，开启后有一个按钮，通过选择可以控制目前是否开启。</p>
<p><img src="/../images/image-20230529204718806.png" alt="image-20230529204718806"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>至此，我们完成了如何通过抓包找到模型然后编写JS代码进行实现无限次数的GPT4模型调用，如果觉得写的不错可以给项目点个赞捏， **给大家磕头了ლ(´ڡ&#96;ლ)**。</p>

            
        </div>
    </div>
    <div class="post-tags">
        
        
    </div>
    <a href="/2023/05/30/Infinite-GPT4-Usage/" class="go-post">阅读全文</a>
</div>


        <div class="page-current">
    <div class="prev">
        
    </div>
    <div class="page-index">
        
        <span class="current">1</span>
        
    </div>
    <div class="next">
        
    </div>
</div>

    </div>
    
    <div id="home-card">
        <div id="card-div">
    <div class="card-style">
        <div class="avatar">
            <img src="/images/avatar.gif" alt="avatar" />
        </div>
        <div class="name">Ding Li</div>
        <div class="description">
            <p>Description<br>你好， 这里是Linkedlist771的个人博客，主要记录一些学习笔记，谢谢你的访问！</p>

        </div>
        
        <div class="icon-links">
            
            <span class="icon-link">
                <a target="_blank" rel="noopener" href="https://github.com/linkedlist771">
                    <i
                        class="fa-brands fa-github fa-fw"
                    ></i>
                </a>
            </span>
            
            <span class="icon-link">
                <a href="/null">
                    <i
                        class="fa-brands fa-twitter fa-fw"
                    ></i>
                </a>
            </span>
            
            <span class="icon-link">
                <a target="_blank" rel="noopener" href="http://wpa.qq.com/msgrd?v=3&uin=2317431442&site=qq&menu=yes">
                    <i
                        class="fa-brands fa-qq fa-fw"
                    ></i>
                </a>
            </span>
            
            <span class="icon-link">
                <a href="mailto:213193509seu@gmail.com">
                    <i
                        class="fa-solid fa-envelope fa-fw"
                    ></i>
                </a>
            </span>
            
        </div>
        
        
        <div class="friend-links">
            
            <div class="friend-link">
                <a target="_blank" rel="noopener" href="https://argvchs.github.io">Argvchs</a>
            </div>
            
            <div class="friend-link">
                <a href="/www.803366.xyz">Stmoonar</a>
            </div>
            
        </div>
        
    </div>
</div>

    </div>
    
</div>

                    <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2023 LinkedList&#39;s Blog
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Ding Li
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

                </div>
            </transition>
            
            <transition name="fade">
                <div id="preview" ref="preview" v-show="previewShow">
                    <img id="preview-content" ref="previewContent" />
                </div>
            </transition>
            
        </div>
        <script src="/js/main.js"></script>
        
    </body>
</html>
